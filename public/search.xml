<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[es5集群磁盘扩容]]></title>
    <url>%2F2019%2F10%2F28%2F22-es%E9%9B%86%E7%BE%A4%E7%A3%81%E7%9B%98%E6%89%A9%E5%AE%B9%2F</url>
    <content type="text"><![CDATA[es集群磁盘不足,对磁盘扩容遇到一些的问题 重启集群前，先设置集群停止分片移动：12345curl -XPUT http://localhost:9200/_cluster/settings -d '&#123;"transient" : &#123;"cluster.routing.allocation.enable" : "none"&#125;&#125;' 对磁盘进行扩容,每次操作一个节点123456789101112131415# 直接扩容磁盘到2T//针对ext4文件格式的操作系统（如CentOS6）：//umount /dev/vdbe2fsck -f /dev/vdbresize2fs /dev/vdbmount /dev/vdb /data# 或者新增 2T云盘/dev/vdcumount /data/mkdir /data2mount /dev/vdb /data2mkfs.ext4 /dev/vdcmount /dev/vdc /datacp -ra /data2/* /data/ 重启之后，恢复分片自动分配：12345curl -XPUT http://localhost:9200/_cluster/settings -d '&#123;"transient" : &#123;"cluster.routing.allocation.enable" : "all"&#125;&#125;' 如果需要下线其中的节点, 先将分片都转义到其他节点123456# 执行以下命令会自动将10.10.0.1 节点上的分片全部迁移到其他机器, 等待迁移完成, 将改空机器下线即可curl -XPUT 127.0.0.1:9200/_cluster/settings -d '&#123;"transient" :&#123;"cluster.routing.allocation.exclude._ip" : "10.10.0.1"&#125;&#125;' 另外对于 path.data 配置多快盘的问题1234比如es8配置了三块盘:/disk4/data -&gt; sde, /disk5/data -&gt; sdf, disk6/data -&gt; sdg这里注意 es node的data path尽量保证盘的大小差别不要太大, sde,sdf,sdg的大小保障差不多, 否则由于es shard 均衡的时候可能会优先分配到磁盘大的目录, 可能会导致sde(假如这个磁盘最大)的IO高, 而sdf等IO低 简单的配置信息elasticsearch512345678910111213cluster.name: es-devnode.name: es1-upath.data: /data/es/datapath.logs: /data/es/logsnetwork.host: 0.0.0.0discovery.zen.ping.unicast.hosts: ["10.10.0.1:9300","10.10.0.2:9300","10.10.0.3:9300","10.10.0.4:9300"]http.cors.enabled: truehttp.cors.allow-origin: "*"xpack.security.enabled: falsebootstrap.system_call_filter: falsethread_pool.bulk.queue_size: 3000# 防止脑裂discovery.zen.minimum_master_nodes: 2]]></content>
      <categories>
        <category>elk</category>
        <category>elasticsearch5</category>
      </categories>
      <tags>
        <tag>elasticsearch5</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[流量复制工具gor]]></title>
    <url>%2F2019%2F10%2F28%2F21-%E6%B5%81%E9%87%8F%E5%A4%8D%E5%88%B6%E5%B7%A5%E5%85%B7gor%2F</url>
    <content type="text"><![CDATA[Gor 是一款go语言实现的简单的http流量复制工具，它的主要目的是使你的生产环境HTTP真实流量在测试环境和预发布环境重现 流量复制工具 下载安装github下载地址: https://github.com/buger/goreplay/releases 1234tar -xvf gor_1.0.0_x64.tar.gzmv gor /usr/bin/which gor 命令123456789101112131415161718192021222324252627282930311 保存请求到文件# 将本机所有80请求保存到gor-20171120_0.log文件(注意会生成很多文件)gor --input-raw :80 --output-file gor-%Y%m%d.log# --output-file-append 会生成gor-20171120.log文件gor --input-raw :80 --output-file gor-%Y%m%d.log --output-file-append2 根据文件回放请求# 镜像qps回放gor --input-file gor-aaaa-20171120.log --output-http aaaa-dev.test.com# 两倍镜像qps回放gor --input-file "gor-aaaa-20171120.log|200%" --output-http aaaa-dev.test.com3 过滤url后保存请求到文件# 排除s.test.com的请求gor --input-raw :80 --output-file gor-%Y%m%d.log --output-file-append --http-disallow-header "Host: s.test.com" --http-disallow-header "Host: www.test.com" --http-disallow-header "Host: bbs.test.com"# 只存储aaaa.test.com的请求gor --input-raw :80 --output-file gor-aaaa-%Y%m%d.log --output-file-append --http-allow-header "Host: aaaa.test.com"# https的不能抓包gor --input-raw :443 --output-file gor-ssl-aaaa-%Y%m%d.log --output-file-append --http-allow-header "Host: aaaa.test.com"4 在线镜像复制请求# 将生产aaaa.test.com的请求复制到 aaaa-dev.test.com 环境!gor --input-raw :80 --output-http "aaaa-dev.test.com" --http-allow-header "Host: aaaa.test.com" 离线文件编辑123456文件的每个请求通过 如下字符串分割!ð&lt;9f&gt;&lt;90&gt;µð&lt;9f&gt;&lt;99&gt;&lt;88&gt;ð&lt;9f&gt;&lt;99&gt;&lt;89&gt;并且第一行是 请求的唯一码? 和时间戳!1 9b366a8eab8d6cb8e557cb3bf43f69c36612cffb 1511165572419843000所以可录制比如半小时的然后窃取需要的时间段! 问题 https 不能抓包! 通过添加代理, gor抓取8000端口 1234567891011121314151617181920212223# SSL terminationserver &#123; listen 443 ssl; server_name aaaa.test.com; ssl_certificate /etc/ssl/nginx/server.crt; ssl_certificate_key /etc/ssl/nginx/server.key; location / &#123; proxy_set_header Host $host; proxy_pass http://localhost:8000; &#125;&#125;server &#123; listen 8000; server_name aaaa.test.com; location / &#123; proxy_set_header Host $host; proxy_pass http://production_shop_api_site; &#125;&#125;]]></content>
      <categories>
        <category>流量复制工具</category>
        <category>gor</category>
      </categories>
      <tags>
        <tag>gor</tag>
        <tag>http流量复制工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s搭建mysql5.7.24主从]]></title>
    <url>%2F2019%2F10%2F24%2F20-k8s%E6%90%AD%E5%BB%BAmysql5-7-24%E4%B8%BB%E4%BB%8E%2F</url>
    <content type="text"><![CDATA[k8s上简单部署mysql5.7.24主从 k8s搭建mysql5.7.24主从 参考文档利用Kubernetes搭建mysql主从复制集群官方dockerfile 从hub.docker.com拉取官方镜像1docker pull mysql:5.7.24 build镜像 主库master的Dockerfile12345from mysql:5.7.24run sed -i '/\[mysqld\]/a server-id=1\nlog-bin' /etc/mysql/mysql.conf.d/mysqld.cnfCOPY docker-entrypoint.sh /usr/local/bin/ 主库的docker-entrypoint.sh 先从初始镜像取 或者从github对应版本上 123docker run -dti mysql:5.7.24 /bin/bashdocker cp 2bfa6209d120c23:/usr/local/bin/docker-entrypoint.sh . 修改docker-entrypoint.sh 12345678fi# 添加以下内容echo "CREATE USER '$MYSQL_REPLICATION_USER'@'%' IDENTIFIED BY '$MYSQL_REPLICATION_PASSWORD' ;" | "$&#123;mysql[@]&#125;"echo "GRANT REPLICATION SLAVE ON *.* TO '$MYSQL_REPLICATION_USER'@'%' IDENTIFIED BY '$MYSQL_REPLICATION_PASSWORD' ;" | "$&#123;mysql[@]&#125;"echo "FLUSH PRIVILEGES ;" | "$&#123;mysql[@]&#125;"# 添加以上内容echo ls /docker-entrypoint-initdb.d/ &gt; /dev/null build主库镜像 12docker build -t hub.boqii.com/bq/mysql-master:5.7.24 .docker push hub.boqii.com/bq/mysql-master:5.7.24 从库的docker-entrypoint.sh 同上先从初始镜像取 或者从github对应版本上 或复制上面的文件 修改docker-entrypoint.sh 12345678fi# 添加以下内容 echo "STOP SLAVE;" | "$&#123;mysql[@]&#125;" echo "CHANGE MASTER TO master_host='$MYSQL_MASTER_SERVICE_HOST', master_user='$MYSQL_REPLICATION_USER', master_password='$MYSQL_REPLICATION_PASSWORD' ;" | "$&#123;mysql[@]&#125;" echo "START SLAVE;" | "$&#123;mysql[@]&#125;" # 添加以上内容echo ls /docker-entrypoint-initdb.d/ &gt; /dev/null build从库镜像 12docker build -t hub.boqii.com/bq/mysql-slave:5.7.24 .docker push hub.boqii.com/bq/mysql-slave:5.7.24 开始部署 k8s-master-mysql_5.7.24.yml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869---apiVersion: apps/v1beta1kind: StatefulSetmetadata: labels: app: php-mysql-master-dev name: php-mysql-master-dev namespace: dbspec: serviceName: "php-mysql-master-dev" replicas: 1 selector: matchLabels: app: php-mysql-master-dev template: metadata: labels: app: php-mysql-master-dev spec: containers: - name: php-mysql-master-dev image: hub.boqii.com/bq/mysql-master:5.7.24 ports: - containerPort: 3306 name: db-port resources: requests: cpu: "50m" limits: cpu: "1000m" env: - name: MYSQL_ROOT_PASSWORD value: "Boqii.123" - name: MYSQL_REPLICATION_USER value: "repl" - name: MYSQL_REPLICATION_PASSWORD value: "7a5b21ac65712bd95e39d3c1" volumeMounts: - name: order-master-dev-data mountPath: /var/lib/mysql - name: order-master-dev-cfg mountPath: /etc/mysql volumes: - name: order-master-dev-data hostPath: path: /data/k8s-container/php-mysql-dev/master/data - name: order-master-dev-cfg hostPath: path: /data/k8s-container/php-mysql-dev/master/etc-mysql---kind: ServiceapiVersion: v1metadata: labels: app: php-mysql-master-dev name: php-mysql-master-dev-service namespace: dbspec: type: NodePort ports: - port: 3306 name: db-port targetPort: 3306 nodePort: 23306 protocol: TCP selector: app: php-mysql-master-dev k8s-slave-mysql_5.7.24.yml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172---apiVersion: apps/v1beta1kind: StatefulSetmetadata: labels: app: php-mysql-slave-dev name: php-mysql-slave-dev namespace: dbspec: serviceName: "php-mysql-slave-dev" replicas: 1 selector: matchLabels: app: php-mysql-slave-dev template: metadata: labels: app: php-mysql-slave-dev spec: containers: - name: php-mysql-slave-dev image: hub.boqii.com/bq/mysql-slave:5.7.24 ports: - containerPort: 3306 name: db-port resources: requests: cpu: "50m" limits: cpu: "1000m" env: - name: MYSQL_ROOT_PASSWORD value: "Boqii.123" - name: MYSQL_REPLICATION_USER value: "repl" - name: MYSQL_REPLICATION_PASSWORD value: "7a5b21ac65712bd95e39d3c1" - name: MYSQL_MASTER_SERVICE_HOST value: "php-mysql-master-dev-service" volumeMounts: - name: order-slave-dev-data mountPath: /var/lib/mysql - name: order-slave-dev-cfg mountPath: /etc/mysql volumes: - name: order-slave-dev-data hostPath: path: /data/k8s-container/php-mysql-dev/slave/data - name: order-slave-dev-cfg hostPath: path: /data/k8s-container/php-mysql-dev/slave/etc-mysql---kind: ServiceapiVersion: v1metadata: labels: app: php-mysql-slave-dev name: php-mysql-slave-dev-service namespace: dbspec: type: NodePort ports: - port: 3306 name: db-port targetPort: 3306 nodePort: 23307 protocol: TCP selector: app: php-mysql-slave-dev 问题总结 从库的replay log名字会根据docker主机名变化, 也可以写在配置文件 12# Dockerfile中可以添加run sed -i '/\[mysqld\]/a relay-log-index=php-mysql-shoporder-slave-dev-relay-bin.index' /etc/mysql/mysql.conf.d/mysqld.cnf 注意MYSQL_MASTER_SERVICE_HOST 变量的配置, 根据你master的service变化 其次我docker-entrypoint.sh 文件几次手动从页面复制粘贴下来的导致各种语法错误,这里建议找到对的版本从github克隆, 或者从mysql:5.7.24镜像中cp 配置etc-mysql/mysql.conf.d/mysqld.cnf 12345678[mysqld]# 从库配置read_only=1character-set-server=utf8# 1 去掉STRICT_TRANS_TABLES 表NOT NULL时无法创建表# 2 修改NO_ZERO_DATE为ALLOW_INVALID_DATES 允许’0000-00-00’#sql_mode='ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION'sql_mode='ONLY_FULL_GROUP_BY,NO_ZERO_IN_DATE,ALLOW_INVALID_DATES,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION' 配置etc-mysql/conf.d/mysql.cnf 123[mysql]no-auto-rehashdefault-character-set=utf8 附录master配置docker-entrypoint.shslave配置docker-entrypoint.sh]]></content>
      <categories>
        <category>mysql</category>
        <category>k8s</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell中gt和>的区别]]></title>
    <url>%2F2019%2F10%2F17%2F19-shell%E4%B8%ADgt%E5%92%8C%3E%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[shell中 gt 和 &gt; 的一些相关问题介绍和测试 以下是bash的测试, 注意如果你是zsh可能会不同喔😯 [[]] , [] 和test比较 [] 和test: 两者是一样的，在命令行里test expr和[ expr ]的效果相同。test中可用的比较运算符只有==和!=，两者都是用于字符串比较的，不可用于整数比较，整数比较只能使用-eq, -gt这种形式。通过which [ 和which test 可以看到是命令 [] 和test 例子 1234567[root@dk-centos6 ~]# a="abcdef"[root@dk-centos6 ~]# test "$a" = "abcdef"[root@dk-centos6 ~]# echo $?0[root@dk-centos6 ~]# [ "$a" = "abcdef" ][root@dk-centos6 ~]# echo $?0 [[ ]]具体功能: [[是 bash 程序语言的关键字。并不是一个命令，[[ ]] 结构比[ ]结构更加通用。在[[和]]之间所有的字符都不会发生文件名扩展或者单词分割，但是会发生参数扩展和命令替换。 支持字符串的模式匹配（使用=~操作符时甚至支持shell的正则表达 式）,右边的字符串不加双引号的情况,可以把右边作为模式. 比如[[ hello == hell? ]]，结果为真。当然加引号就是文本字符串比较. 使用[[ … ]]条件判断结构，而不是[ … ]，能够防止脚本中的许多逻辑错误。比如，&amp;&amp;、||、&lt;和&gt; 操作符能够正常存在于[[ ]]条件判断结构中，但是如果出现在[ ]结构中的话，会报错。比如可以直接使用if [[ $a != 1 &amp;&amp; $a != 2 ]], 如果不适用双括号, 则为if [ $a -ne 1] &amp;&amp; [ $a != 2 ]或者if [ $a -ne 1 -a $a != 2 ]。 纯数字比较 &gt; 通过比较ASCII值,gt仅能比较数字123456789101112[root@dk-centos6 ~]# [ 2 \&gt; 1 ][root@dk-centos6 ~]# echo $?0[root@dk-centos6 ~]# [ 2 -gt 1 ][root@dk-centos6 ~]# echo $?0[root@dk-centos6 ~]# [[ 2 &gt; 1 ]][root@dk-centos6 ~]# echo $?0[root@dk-centos6 ~]# [[ 2 -gt 1 ]][root@dk-centos6 ~]# echo $?0 字符串比较 单括号中如果要比较符号 “&lt;” “&gt;”, 需要转义, 否则判断结果错误123456789[root@dk-centos6 ~]# [ "b" &gt; "a" ][root@dk-centos6 ~]# echo $?0[root@dk-centos6 ~]# [ "b" &lt; "a" ][root@dk-centos6 ~]# echo $?0[root@dk-centos6 ~]# [ "b" \&lt; "a" ][root@dk-centos6 ~]# echo $?1 双括号不用转义 , 直接执行即可123456[root@dk-centos6 ~]# [[ "b" &gt; "a" ]][root@dk-centos6 ~]# echo $?0[root@dk-centos6 ~]# [[ "b" &lt; "a" ]][root@dk-centos6 ~]# echo $?1]]></content>
      <categories>
        <category>linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[收藏链接]]></title>
    <url>%2F2019%2F10%2F17%2F18-%E6%94%B6%E8%97%8F%E9%93%BE%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[记录一些好的网址 云原生 云原生图书编年史 云原生大佬博客汇总]]></content>
      <categories>
        <category>网址</category>
        <category>收藏</category>
      </categories>
      <tags>
        <tag>收藏</tag>
        <tag>网址</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown一些写法记录]]></title>
    <url>%2F2019%2F10%2F16%2F17-markdown%E4%B8%80%E4%BA%9B%E5%86%99%E6%B3%95%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[记录一些需要注意的写法,markdown 是支持html语法的 这里想写一个居中的标题和图片1234&lt;center&gt;&lt;img src="http://zhangzw001.github.io/images/dockerniu.jpeg" width = "100" height = "100" style="border: 0"/&gt;&lt;font color="blue" face="黑体" size=5&gt; Dockerfile &lt;/font&gt;&lt;/center&gt; 效果点击查看]]></content>
      <categories>
        <category>markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dockerfile介绍]]></title>
    <url>%2F2019%2F10%2F16%2F16-dockerfile%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[Dockerfile 本文摘录于: 如何快速将容器云镜像大小精简98%？ Dockerfile 文件有自己的书写格式和支持的命令，常用的Dockerfile 指令有： FROM 指定基镜像。 MAINTAINER 设置镜像的作者信息，如作者姓名、邮箱等。 COPY 将文件从本地复制到镜像，拷贝前需要保证本地源文件存在。 ADD 与 COPY 类似，复制文件到镜像。不同的是，如果文件是归档文件（tar, zip, tgz, xz 等），会被自动解压。 ENV 设置环境变量，格式: ENV key=value或ENV key value，运行容器后，可直接在容器中使用。 EXPOSE 暴露容器中指定的端口，只是一个声明，主要用户了解应用监听的端口。 VOLUME 挂载卷到容器，需要注意的是，保存镜像时不会保存卷中的数据。 WORKDIR 设置当前工作目录，后续各层的当前目录都被指定。 RUN 在容器中运行指定的命令。 CMD 容器启动时运行的命令。Dockerfile 中可以有多个 CMD 指令，但只有最后一个生效。CMD 可以被 docker run 之后的参数替换。 ENTRYPOINT 设置容器启动时运行的命令。Dockerfile 中可以有多个 ENTRYPOINT 指令，但只有最后一个生效。CMD 或 docker run 之后的参数会被当做参数传递给 ENTRYPOINT，这个是与CMD的区别。 容器的原理 容器镜像中最重要的概念就是layers，即镜像层。 容器的原理 镜像层依赖于一系列的底层技术，比如文件系统(filesystems)、写时复制(copy-on-write)、联合挂载(union mounts)等技术查看Docker 官方文档https://docs.docker.com/storage/storagedriver/进行学习。 每条指令都创建一个镜像层，会增加镜像的大小 下面看个例子这里我有一个1.2M的镜像 12docker images|grep busyboxbusybox latest 19485c79a9bb 5 weeks ago 1.22MB 我们基于busybox写一个Dockerfile来build 1234567#cat Dockerfilefrom busybox:latestrun mkdir /tmp/dir \ &amp;&amp; dd if=/dev/zero of=/tmp/dir/file1 bs=1M count=10run rm -f /tmp/dir/file1 执行build 1234567891011121314151617docker build -t busybox-test .Sending build context to Docker daemon 2.048kBStep 1/3 : from busybox:latest ---&gt; 19485c79a9bbStep 2/3 : run mkdir /tmp/dir &amp;&amp; dd if=/dev/zero of=/tmp/dir/file1 bs=1M count=10 ---&gt; Running in 0426f92c77ed10+0 records in10+0 records out10485760 bytes (10.0MB) copied, 0.003785 seconds, 2.6GB/sRemoving intermediate container 0426f92c77ed ---&gt; 5ec75db090c9Step 3/3 : run rm -f /tmp/dir/file1 ---&gt; Running in 540e7d0a5aeaRemoving intermediate container 540e7d0a5aea ---&gt; 00041489cc0eSuccessfully built 00041489cc0eSuccessfully tagged busybox-test:latest 查看image大小 123docker images|grep busyboxbusybox-test latest 00041489cc0e 10 minutes ago 11.7MBbusybox latest 19485c79a9bb 5 weeks ago 1.22MB ??? 我不是rm删除了创建的/tmp/dir/file1 文件吗? 难道它还在? 来,我们测试一下 12# 查看目录下是否有文件docker run -ti busybox-test ls /tmp/dir 结果显然是空… 喔,,, 因为”在Dockerfile中，每条指令都会创建一个镜像层，继而会增加镜像整体的大小”, 在看我们写的Dockerfile,我们第一个run 执行的时候, 这里假装叫 (run1层), 我们生成了file1文件当执行第二个run的时候, 我们处在了 (run2层), (run1层)已经是父层,是个只读层了,只有当前层可写, 虽然我们在 (run2层)删除了这个文件,但删除的仅仅是份拷贝而已, 这就是写时复制. 所以以上的优化应该是: 写成一条run 123456789#cat Dockerfilefrom busybox:latestrun mkdir /tmp/dir \ &amp;&amp; dd if=/dev/zero of=/tmp/dir/file1 bs=1M count=10 \ &amp;&amp; rm -f /tmp/dir/file1# builddocker build -t busybox-test2 . 结果显然 1234docker images|grep busyboxbusybox-test2 latest faf8b7d4f140 3 seconds ago 1.22MBbusybox-test latest 00041489cc0e 10 minutes ago 11.7MBbusybox latest 19485c79a9bb 5 weeks ago 1.22MB 虽然说这里的测试没有干任何事情, 但我们在写Dockerfile的时候需要注意, 两个run之间是两个不同的 可写层! 简单总结精简镜像大小的方法: 121 使用更小的基础镜像,注意一些很小的镜像可能缺少很多依赖库,例如查看redis依赖库 ldd /usr/bin/redis-cli2 合并Dockerfilec指令精简(可以的话写成一条run) 一些小的镜像 1 scratch: 一个空的镜像, 无法pull -.-!!! , 写在Dockerfile是可以的 2 alpine: 5M的linux镜像,有包管理工具apk 123FROM scratchADD alpine-minirootfs-3.10.2-x86_64.tar.gz /CMD ["/bin/sh"] 3 busybox: 1M多的镜像,称为嵌入式linux的瑞士军刀, Linux和unix一些常用的命令]]></content>
      <categories>
        <category>docker</category>
        <category>Dockerfile</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker简介和使用]]></title>
    <url>%2F2019%2F10%2F16%2F15-docker%E7%AE%80%E4%BB%8B%E5%92%8C%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[简单介绍docker docker]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql5.5目录copy方式迁移]]></title>
    <url>%2F2019%2F10%2F15%2F14-mysql%E7%9B%AE%E5%BD%95copy%E6%96%B9%E5%BC%8F%E8%BF%81%E7%A7%BB%2F</url>
    <content type="text"><![CDATA[从现有的一台 从库 全copy data目录到2台新机器上, 再配置mysql主从 目录copy方式迁移 注意 不要删除ibdata1,会导致innodb表不存在 可以不删除ib_logfile0,ib_logfile1, 但my.cnf配置大小一致 区别目录权限为mysql,tmp目录存在 请自行安装好mysql5.5 1234567891 首先停止mysql/etc/init.d/mysqld stop2 同步数据目录到新机器/data/u013 确认新机器上mysql版本并配置/etc/my.cof4 完整迁移时不需要删除内容(innodb_log_file_size = 256M 配置要一致)5 启动mysql 配置主从 1 首先 目录copy方式 同步某个从库到2台新机器并启动完成, 此时两个mysql都开启了slave 2 暂停同步，并设置读写； 123456stop slave;# 该执行仅主库上执行(配置可写)SET GLOBAL read_only=0;reset slave all;-- RESET SLAVE ALL是清除从库的同步复制信息、包括连接信息和二进制文件名、位置-- 从库上执行这个命令后，使用show slave status将不会有输出。 3 2台新的mysql中修改从库slave配置, 连接到新的主库地址(我这里通过域名解析) 12CHANGE MASTER TO MASTER_HOST='a_master.b.com',MASTER_PORT=3306,MASTER_USER='repl_user',MASTER_PASSWORD='xxxx',MASTER_LOG_FILE='m1-master-bin.000001',MASTER_LOG_POS=88; 4 由于本机需要安装mysql5.5和mysql5.7所以注意一下 123456# 初始化指定配置文件/usr/local/mysql57/bin/mysqld --defaults-file=/etc/my57.cnf --initialize-insecure --user=mysql --basedir=/usr/local/mysql57 --datadir=/data/u001# 修改/etc/init.d/mysqld57parse_server_arguments `$print_defaults -c /etc/my57.cnf mysqld server mysql_server mysql.server`$bindir/mysqld_safe --defaults-file=/etc/my57.cnf --pid-file="$mysqld_pid_file_path" $other_args &gt;/dev/null &amp; 报错统计 ERROR 1840 (HY000) at line 24: @@GLOBAL.GTID_PURGED can only be set when @@GLOBAL.GTID_EXECUTED is empty. 1执行reset master; The MySQL server is running with the–read-only option so it cannot execute this statement 1执行 set global read_only=0;]]></content>
      <categories>
        <category>技术文档</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[云原生博客汇总]]></title>
    <url>%2F2019%2F10%2F12%2F13-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%8D%9A%E5%AE%A2%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[记录一些云原生技术博客 来自ServiceMesher[8] 群KaiRen’s Blog Zlatan Eevee 国南之境 博客 | 高策 Kakashi’s Blog Alex Wu’s blog | THINK BIG, START SMALL, DELIVER VALUE TO THE BUSINESS 开元DevOps知识库 - 知识管理，时间管理，自我管理 起风了 茶歇驿站 - Gopher, OpenSource Fans, 成长之路有我相伴。 Polar Snow Documentation 云原生实验室 - 米开朗基杨的博客 Jimmy Song - 宋净超的博客|Cloud Native|云原生布道师 漠然的博客 | mritd Blog DevOps – 成长之路 birdben 浮生若梦 CNCF Cloud Native Interactive Landscape 杜屹东的博客 | 学无止境 梦旭随想 ictfox blog CloudNative 架构 我爱西红柿 Doublemine Bingo Huang Arthur Chunqi Li’s Blog Archive | Arthur Chunqi Li’s Blog IT技术工作学习折腾笔记 李佶澳的博客 墨荷琼林官网-编程日志 Archive - Nolla Tomoya’s Blog 君无止境 Jamin Zhang roc - imroc.io|roc的博客|Cloud Native|Kubernetes|Go|Golang Blog | Sysdig sleele的博客 TauCeti blog · TauCeti blog 水晶命匣 | 生命在于折腾，折腾万岁！ 苏洋博客 LinuxTOY Infvie’s Blog | 运维SRE社区博客 Solar MoeLove Hwchiu Learning Notekubernetes/SDN/DevOps 存储领域 yangguanjun]]></content>
      <categories>
        <category>技术文档</category>
        <category>网址</category>
        <category>大佬博客</category>
      </categories>
      <tags>
        <tag>云原生</tag>
        <tag>cloud native</tag>
        <tag>大佬博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[awk简单记录]]></title>
    <url>%2F2019%2F10%2F11%2F12-awk%E7%AE%80%E5%8D%95%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[记录一些简单使用 实例1: 计算nginx日志中某个接口的次数和平均响应时间例如我的a.txt nginx日志格式如下12a.b.com 1.1.1.1 [08/Sep/2019:23:57:01 +0800] "GET /v1/actionname?xxxx HTTP/1.1" 200 386 "-" "Mozilla/5.0 (Linux; Android 9; V1831A Build/P00610; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/68.0.3440.91 Mobile Safari/537.36" "-" "0.023"a.b.com 1.1.1.1 [08/Sep/2019:23:57:01 +0800] "GET /v1/actionname2?xxxx HTTP/1.1" 200 386 "-" "Mozilla/5.0 (Linux; Android 9; V1831A Build/P00610; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/68.0.3440.91 Mobile Safari/537.36" "-" "0.016" 这里我只想取出接口名: /v1/actionname 和 0.023 响应时间 首先我取出这两列1234567cat a.txt|awk -F '"' '&#123;print $(NF-1),$2&#125;'|awk -F '?' '&#123;print $1&#125;'|awk '&#123;print $1" "$3&#125;' &gt; b.txtcat b.txt0.023 /v1/actionname0.016 /v1/actionname2... 命令详解12345678&gt; 第一步 响应时间求和&#123;s[$2]+=$1&#125;: 每遇到一个$2,比如遇到/v1/actionname,记录一个数组s[/v1/actionname] = 所有$1的值的总和&gt; 第二步 算接口的次数&#123;m[$2]++&#125;: 每遇到一个$2,比如遇到/v1/actionname,记录一个数组m[/v1/actionname] = 所有$1的个数&gt; 第三步 取平均值# 这里输出csv文件cat b.txt|awk '&#123;m[$2]++&#125; &#123;s[$2]+=$1&#125; ; END &#123;for(i in m) &#123;print s[i]/m[i] "," m[i] "," i&#125;&#125;'|awk -F "," '$2 &gt; 20'|sort -k2nr &gt; test.csv]]></content>
      <categories>
        <category>linux</category>
        <category>awk</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>awk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql简单记录]]></title>
    <url>%2F2019%2F10%2F10%2F11-mysql%E7%AE%80%E5%8D%95%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[简单记录一些mysql知识点 清空表123456789删除表信息的方式有两种 :truncate table table_name;delete * from table_name;注 : truncate操作中的table可以省略，delete操作中的*可以省略truncate、delete 清空表数据的区别 :1&gt; truncate 是整体删除 (速度较快)，delete是逐条删除 (速度较慢)2&gt; truncate 不写服务器 log，delete 写服务器 log，也就是 truncate 效率比 delete高的原因3&gt; truncate 不激活trigger (触发器)，但是会重置Identity (标识列、自增字段)，相当于自增列会被置为初始值，又重新从1开始记录，而不是接着原来的 ID数。而 delete 删除以后，identity 依旧是接着被删除的最近的那一条记录ID加1后进行记录。如果只需删除表中的部分记录，只能使用 DELETE语句配合 where条件 备份12345# 全量锁表备份(不可写)mysqldump --lock-all-tables --all-databases &gt; ALLDB.sql# 仅导出所有表的结构mysqldump --opt -d 数据库名 -u root -p &gt; xxx.sql slave 中修改master_host12345678910# 查看 master.info中信息# 查看 show slave status\G 中 Master_Host# 修改的步骤需要先停止slave1 stop slave ;2 change master to master_host='xxx.xxx.xxx'; 首次配置主库: CHANGE MASTER TO MASTER_HOST='a_master.b.com',MASTER_PORT=3306,MASTER_USER='repl_user',MASTER_PASSWORD='xxxx',MASTER_LOG_FILE='m1-master-bin.000001',MASTER_LOG_POS=88;3 start slave ; mysql问题: navicat连接数据库很慢123456报错: 2013-Lost connection to MYSQL server at 'reading for initial communication packet'说明: 只有windows 的navicat会出现上面报错, windows上通过mysql命令连接时 也很慢#添加如下内容:[mysqld]skip-name-resolve mysql问题: mysql5.7 错误总结-ERROR 1067 (42000): Invalid default value for TIMESTAMP123456show variables like 'sql_mode';+---------------+-------------------------------------------------------------------------------------------------------------------------------------------+| Variable_name | Value |+---------------+-------------------------------------------------------------------------------------------------------------------------------------------+| sql_mode | ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION |+---------------+-------------------------------------------------------------------------------------------------------------------------------------------+ 这是因为sql_mode中的NO_ZEROR_DATE导制的，在strict mode中不允许’0000-00-00’作为合法日期 将上面的NO_ZERO_DATE改为下面的 ALLOW_INVALID_DATES 12set sql_mode='ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,ALLOW_INVALID_DATES,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION';set session sql_mode='ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION'; 上面的设置是临时设置，在重新登陆后，该设置又恢复为NO_ZERO_DATE mysql5.5主+mysql5.7从 问题123ERROR 1794 (HY000): Slave is not configured or failed to initialize properly. You must at least set --server-id to enable either a master or a slave. Additional error messages can be found in the MySQL error log.server_uuid是5.6的gtid特性引入的一个配置，把mysql5.7的 rpl_slave.cc文件中get_master_uuid函数换成5.6对应的函数就可以了。]]></content>
      <categories>
        <category>技术文档</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos6安装nginx1.16+php7.2]]></title>
    <url>%2F2019%2F09%2F27%2F10-centos6%E5%AE%89%E8%A3%85nginx1-16-php7-2%2F</url>
    <content type="text"><![CDATA[记录简单的安装nginx和php的配置,仅供参考 先准备环境123456789# 更新源mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bakcurl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repoyum clean allyum makecacheyum install -y epel-release# 安装一些依赖包yum -y install gcc make cmake ncurses-devel libxml2-devel libtool-ltdl-devel gcc-c++ autoconf automake bison zlib-devel openssl-devel pcre-devel libxml2 libxml2-devel libcurl libcurl-devel autoconf automake libtool-ltdl libtool-ltdl-devel libjpeg libjpeg-turbo-devel libmcrypt-devel libpng-devel centos6编译安装nginx123456789101112131415#首先官网下载1.16cd /usr/local/src/wget http://nginx.org/download/nginx-1.16.0.tar.gztar -xvf nginx-1.16.0.tar.gz# 编译简单的模块./configure --prefix=/usr/local/nginx/ --with-http_ssl_module --with-http_stub_status_module --with-http_stub_status_modulemake -j4make install# 通过启动脚本启动chmod +x /etc/init.d/nginxservice nginx start# 开机启动chkconfig nginx on nginx 启动脚本 /etc/init.d/nginx12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#!/bin/bash# nginx Startup script for the Nginx HTTP Server# it is v.0.0.2 version.# chkconfig: - 85 15# description: Nginx is a high-performance web and proxy server.# It has a lot of features, but it's not for everyone.# processname: nginx# pidfile: /var/run/nginx.pid# config: /usr/local/nginx/conf/nginx.confnginx=/usr/local/nginx/sbin/nginxnginx_config=/usr/local/nginx/conf/nginx.confnginx_pid=/var/run/nginx.pidRETVAL=0prog="nginx"# Source function library.. /etc/rc.d/init.d/functions# Source networking configuration.. /etc/sysconfig/network# Check that networking is up.[ $&#123;NETWORKING&#125; = "no" ] &amp;&amp; exit 0[ -x $nginx ] || exit 0# Start nginx daemons functions.start() &#123;if [ -e $nginx_pid ];then echo "nginx already running...." exit 1fi echo -n $"Starting $prog: " daemon $nginx -c $&#123;nginx_config&#125; RETVAL=$? echo [ $RETVAL = 0 ] &amp;&amp; touch /var/lock/subsys/nginx return $RETVAL&#125;# Stop nginx daemons functions.stop() &#123; echo -n $"Stopping $prog: " killproc $nginx RETVAL=$? echo [ $RETVAL = 0 ] &amp;&amp; rm -f /var/lock/subsys/nginx /usr/local//nginx/logs/nginx.pid&#125;reload() &#123; echo -n $"Reloading $prog: " #kill -HUP `cat $&#123;nginx_pid&#125;` killproc $nginx -HUP RETVAL=$? echo&#125;# See how we were called.case "$1" instart) start ;;stop) stop ;;reload) reload ;;restart) stop start ;;status) status $prog RETVAL=$? ;;*) echo $"Usage: $prog &#123;start|stop|restart|reload|status|help&#125;" exit 1esacexit $RETVAL nginx.conf简单配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697user nobody nobody;worker_processes auto;worker_rlimit_nofile 102400;pid /var/run/nginx.pid;events &#123; use epoll; worker_connections 102400;&#125;http &#123; log_format main '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for"'; ###定义一个log_format log_format main '[ $host $request_time $upstream_addr $upstream_response_time ] ' '$status ' '$remote_addr - $remote_user [$time_local] "$request" ' '$body_bytes_sent "$http_referer" "$http_user_agent" "$http_x_forwarded_for " "$bytes_sent" " $request_body"' ; ###日志目录配置 #日志全部写入/nginx_logs/access.log 文件中。关闭最后两个server_name的日志 access_log /data/nginx_logs/access.log server_name_main; error_log /data/nginx_logs/error.log notice; ###杂项配置 charset utf-8; #server name的hash表， server_names_hash_bucket_size 128; #请求头如果过小，那么会引起400错误。一般如果cookie过大，会引起问题。getconf PAGESIZE系统分页 client_header_buffer_size 8k; client_body_buffer_size 512k; large_client_header_buffers 16 16k; client_max_body_size 30m; sendfile on; tcp_nopush on; keepalive_timeout 60; tcp_nodelay on; #fastcgi通用配置 fastcgi_connect_timeout 600; fastcgi_send_timeout 600; fastcgi_read_timeout 600; fastcgi_buffer_size 128k; fastcgi_buffers 8 256k; fastcgi_busy_buffers_size 256k; fastcgi_temp_file_write_size 256k; ###代理有关的配置 proxy_connect_timeout 600; proxy_read_timeout 600; proxy_send_timeout 600; proxy_buffer_size 512k; proxy_buffers 6 512k; proxy_busy_buffers_size 512k; proxy_temp_file_write_size 512k; #或许在于测试,代理服务器不主动关闭客户端，防止499错误 proxy_ignore_client_abort on; ###gzip配置 gzip on; gzip_min_length 1k; gzip_buffers 4 16k; gzip_http_version 1.0; gzip_comp_level 2; gzip_types text/plain application/x-javascript text/css application/xml; gzip_vary on; include /usr/local/nginx/conf/mime.types; default_type application/octet-stream; # 隐藏nginx版本信息 server_tokens off; server &#123; listen 80 default_server; server_name _; #server_name localhost; index index.html index.htm; root html; deny all; location / &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125;&#125; centos6编译安装php712345678910111213141516# 首先安装freetype2.4tar -xvf freetype-2.4.0.tar.gzcd freetype-2.4.0./configure --prefix=/usr/local/freetypemake -j4 &amp;&amp; make install# 编译php7(不需要的可以去掉)tar -xvf php-7.2.2.tar.gzcd php-7.2.2./configure --prefix=/usr/local/php --with-libxml-dir=/usr/ --with-pdo-mysql=mysqlnd --with-zlib --with-libxml-dir --with-openssl --enable-mysqlnd --enable-mbstring --with-config-file-path=/usr/local/php/etc/ --with-config-file-scan-dir=/usr/local/php/etc/conf.d --enable-fpm --with-freetype-dir=/usr/local/freetype --with-jpeg-dir --with-png-dir --with-gd --enable-gd-native-ttf --enable-pdo --enable-mbstring --enable-bcmathmake -j 4 &amp;&amp; make install# 安装composercurl -sS https://getcomposer.org/installer | php &amp;&amp; mv composer.phar /usr/bin/composer 配置1234567891011# php.ini配置(具体配置内容自行修改)cp php.ini-production /usr/local/php7/etc/php.inicp /usr/local/php7/etc/php-fpm.conf.default /usr/local/php7/etc/php-fpm.confcp /usr/local/php7/etc/php-fpm.d/www.conf.default /usr/local/php7/etc/php-fpm.d/www.conf# 启动脚本cp ./sapi/fpm/init.d.php-fpm /etc/init.d/php-fpmchmod +x /etc/init.d/php-fpm# 创建linkln -s /usr/local/php7 /usr/local/php 启动php-fpm12service php-fpm startchkconfig php-fpm on]]></content>
      <categories>
        <category>技术文档</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>php7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux遇到一些问题统计总结]]></title>
    <url>%2F2019%2F09%2F26%2F9-linux%E9%81%87%E5%88%B0%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E7%BB%9F%E8%AE%A1%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[记录一些Linux,nginx或其他服务一些问题 linux问题: tcpdump抓包tcp第三次握手ack为1 执行命令监听: tcpdump -n port 80 (想要详细信息加 -vv) 客户端 telnet x.x.x.x 80 日志如下: 123456tcpdump -n port 80tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on enp0s3, link-type EN10MB (Ethernet), capture size 262144 bytes11:16:40.689157 IP 172.16.54.141.53444 &gt; 172.16.53.106.http: Flags [SEW], seq 1306124348, win 65535, options [mss 1460,nop,wscale 5,nop,nop,TS val 458678777 ecr 0,sackOK,eol], length 011:16:40.689724 IP 172.16.53.106.http &gt; 172.16.54.141.53444: Flags [S.E], seq 1553518959, ack 1306124349, win 64308, options [mss 1410,sackOK,TS val 4208119240 ecr 458678777,nop,wscale 7], length 011:16:40.690320 IP 172.16.54.141.53444 &gt; 172.16.53.106.http: Flags [.], ack 1, win 4106, options [nop,nop,TS val 458678778 ecr 4208119240], length 0 这里第一和第二次握手都没有问题, 第三次 ack 1, 并非是seq+1 这里提一下ACK, ACK 是确认值, ack 是确认编号, 第一次握手ACK=0,在第二次握手开始ACK=1, 而ack是=seq+1(收到的随机数+1) 那么这里ack 1 是啥呢? … 应该就是默认tcpdump 显示成相对值了, 通过-S 参数会显示绝对值 执行命令监听: tcpdump -S -n port 8012345tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on enp0s3, link-type EN10MB (Ethernet), capture size 262144 bytes11:16:54.806628 IP 172.16.54.141.53516 &gt; 172.16.53.106.http: Flags [S], seq 316359286, win 65535, options [mss 1460,nop,wscale 5,nop,nop,TS val 458692791 ecr 0,sackOK,eol], length 011:16:54.806861 IP 172.16.53.106.http &gt; 172.16.54.141.53516: Flags [S.], seq 1113466641, ack 316359287, win 64308, options [mss 1410,sackOK,TS val 4208133357 ecr 458692791,nop,wscale 7], length 011:16:54.807576 IP 172.16.54.141.53516 &gt; 172.16.53.106.http: Flags [.], ack 1113466642, win 4106, options [nop,nop,TS val 458692792 ecr 4208133357], length 0 三次握手图 四次挥手图 linux问题: 禁ping12345678# 一次性修改echo 1 &gt; /proc/sys/net/ipv4/icmp_echo_ignore_all# 开机自动修改echo 1 &gt; /proc/sys/net/ipv4/icmp_echo_ignore_all# 永久禁用,加入到/etc/sysctl.confnet.ipv4.icmp_echo_ignore_all=1 linux问题: 文件锁问题1234567问题描述: php slowlog 出现session_start() 慢问题原因: 我们这边有A 和B 两个二级域名,A 会请求 B, 并且由于测试环境在同一台服务器,公用一个php,所以在发生调用的时候同时写了session,而php的sessions配置是默认的file方式, 这就造成了锁的问题问题解决: 1. 修改代码部分2. php的session配置改成redis session.save_handler = redis session.save_path = "tcp://x.x.x.x:xxxx" linux问题: 内存释放问题123456问题描述: 开发这边写了个统计脚本, 占用49G内存, 从日志发现脚本已经全部执行完成, 但是php脚本依然存在问题原因: 通过 strace -p pid 观察进程, 发现是持续性的做内存释放操作 munmap(0x7f6db77ad000, 266240) = 0持续执行munmap函数是因为一直在释放内存(毕竟49G), 结果 =0 说明内存释放执行函数是返回正常了问题解决: 1. 修改代码降低内存2. 等待一段时间内存会释放完成(测试80分钟释放完毕) nginx问题: 静态文件分离对于一般的nginx+php的方式, 我们php采用nobody用户,而代码/lumen采用web-www用户, 这样的好处是页面访问到/lumen时是nobody用户, 是无法修改代码的 可能我们需求是上用户upload图片等, 这时候就可能被传上某个a.php, 这就有可能被代码注入(一般来说图片是放cdn,配置单独域名回源的,这里是直接存在项目目录) 所以为了防止代码注入,我们需要限制upload目录的访问权限 1234# nginx配置如下 location ~ /images/.*\.(gif|jpg|jpeg|png)$ &#123; root /lumen/storage/uploads/; &#125; 这样我们图片传到 /lumen/storage/uploads/images/ 目录, 访问是 www.xxx.com/images/x.png 来访问 且不允许其他类型文件访问. nginx问题: root 和alias在配置文件映射的时候，如果使用了正则表达式，那么可能会出现无法访问文件，nginx可能会将所有的文件都映射成为文件夹，导致文件映射失败的情况出现； root的例子 1234location /a/ &#123; root /lumen/public;&#125;这里实际访问的路径: www.xxx.com/a/ -&gt; /lumen/public/a/ alias的例子 12345# 注意这里目录最后加上/location /a/ &#123; alias /lumen/public/;&#125;这里实际访问的路径: www.xxx.com/a/ -&gt; /lumen/public/ nginx问题: 隐藏版本信息123Syntax: server_tokens on | off | build | string;Default: server_tokens on;Context: http, server, location nginx问题: 日志出现encode内容如何查看12# python2 执行decode&gt;&gt;&gt; print "\x22content\x22\x0D\x0A\x0D\x0A\xE8\x8A\x8A\xE8\x8A\x8A\xE8\xBF\x98\xE6\x80\x95\xE5\xA6\x9E\xE5\xA6\x9E\xE4\xB8\x8D\xE8\x80\x81\xE5\xAE\x9E\xEF\xBC\x8C\xE7\x89\xB9\xE5\x9C\xB0\xE8\xBF\x87\xE6\x9D\xA5\xE8\xA7\x86\xE5\xAF\x9F\xE4\xB8\x80\xE4\xB8\x8B\x0D\x0A".decode('utf-8') nginx问题: default配置未设置nginx 未设置default时, 如果直接访问服务器外网ip, 会去请求到第一个匹配的server段, 有可能会请求到后端的服务器的内容, 这很有可能暴露我们不想暴露的服务一般来说开头添加如下配置 123456 server &#123; listen 80 default_server; listen [::]:80 default_server; server_name _; deny all;&#125; nginx 配置已经配置域名方式访问, 如果访问ip会返回403, 正常来说返回403已经不会对服务器造成压力了 可是万万没想到虽然返回了403, 但是也有700字节大小, 大量请求对小带宽来说还是有压力的 123456789101112# server &#123; listen 80 default_server; listen [::]:80 default_server; server_name _; return 499; &#125;#其他location,if配置,if ($host != a.example.com) &#123; return 499;&#125;]]></content>
      <categories>
        <category>技术文档</category>
        <category>linux</category>
        <category>问题总结</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql5.7二进制部署]]></title>
    <url>%2F2019%2F09%2F26%2F8-mysql5-7%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[二进制方式部署mysql5.7 下载glibc二进制包12345#打开下载页面, 可能会有小版本更新(注意：选择操作系统时选Linux-Generic）https://dev.mysql.com/downloads/mysql/5.7.html#downloads# 最新的可能有小版本变化wget https://cdn.mysql.com/Downloads/MySQL-5.7/mysql-5.7.24-linux-glibc2.12-x86_64.tar.gz 安装配置1234567891011121314151617181920212223242526272829303132333435363738394041tar -xvf mysql-5.7.24-linux-glibc2.12-x86_64.tar.gzmv mysql-5.7.24-linux-glibc2.12-x86_64 /usr/local/cd /usr/local/# 我的镜像是安装过5.5mysql, 所以需要mv一下mv mysql mysql-5.5.37# 由于以前安装过php指定了该mysq目录, 这可能导致以前安装的php缺少libmysqlclient.so.18ln -s /usr/local/mysql-5.5.37/lib/libmysqlclient.so.18 /usr/local/mysql-5.7.24-linux-glibc2.12-x86_64/lib/libmysqlclient.so.18ln -s mysql-5.7.24-linux-glibc2.12-x86_64 mysql# 添加启动文件\cp mysql/support-files/mysql.server /etc/init.d/mysqldecho "PATH=$PATH:/usr/local/mysql/bin/" &gt;&gt;~/.bashrc# 可选wget http://centos.mirrors.ucloud.cn/centos/6/os/x86_64/Packages/numactl-2.0.9-2.el6.x86_64.rpmyum localinstall numactl-2.0.9-2.el6.x86_64.rpm\rm numactl-2.0.9-2.el6.x86_64.rpmuseradd mysql# 配置下mysql的数据目录cd /data/mkdir u01mkdir u02chown -R mysql.mysql u01chown -R mysql.mysql u02chmod 750 u01chmod 750 u02cd /data/u01/# 初始化/usr/local/mysql/bin/mysqld --initialize-insecure --user=mysql --basedir=/usr/local/mysql --datadir=/data/u01cat auto.cnf# 启动服务 (在这之前准备好 /etc/my.cnf)/etc/init.d/mysqld start# 记录下variablesmysql -e "show global variables" &gt;mysql_option_default.log my.cnf123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172[client]port = 3306socket = /data/u01/mysql.sock[mysql]prompt="\u@m1-u [\d]&gt; "no-auto-rehash[mysqld]user = mysqlport = 3306basedir = /usr/local/mysqldatadir = /data/u01socket = /data/u01/mysql.sockpid-file = /data/u01/m1-u.pidtmpdir = /data/u02server-id = 1001character-set-server = utf8skip_name_resolve = 1innodb_file_per_table = 1explicit_defaults_for_timestamp = 0# buffer&amp;cachetable_open_cache = 100table_definition_cache = 400table_open_cache_instances = 64sort_buffer_size = 4Mjoin_buffer_size = 4Mread_buffer_size = 8Mread_rnd_buffer_size = 4M# thread&amp;connectionthread_stack = 256Kthread_cache_size = 768back_log = 1024max_connections = 3000max_connect_errors = 1000000# temptabletmp_table_size = 32Mmax_heap_table_size = 32M# networkmax_allowed_packet = 32M#lock_wait_timeout = 3600#interactive_timeout = 600#wait_timeout = 600# query cachequery_cache_size = 0query_cache_type = 0# 设置errorlog、slowlog和generallog的时区，默认UTClog_timestamps = SYSTEM# error-loglog_error = /data/u02/mysqld.log# slow-logslow_query_log = 1slow_query_log_file = /data/u02/slow.loglong_query_time = 0.1log_queries_not_using_indexes =1log_throttle_queries_not_using_indexes = 60min_examined_row_limit = 100log_slow_admin_statements = 1log_slow_slave_statements = 1# general log#general-log = 1general_log_file=/data/u02/query.log# binlogbinlog_format = rowbinlog_checksum = 1log-bin = /data/u02/bdm1-binlog-bin-index = /data/u02/bdm1-bin.indexsync_binlog = 0binlog_cache_size = 4Mmax_binlog_cache_size = 2Gmax_binlog_size = 512Mexpire_logs_days = 15# GTIDgtid_mode = onenforce_gtid_consistency = 1log_slave_updates# Replicationmaster_info_repository = TABLErelay_log_info_repository = TABLEslave-rows-search-algorithms = 'INDEX_SCAN,HASH_SCAN'relay_log_recovery = 1relay_log_purge = 1relay-log=/data/u02/bdm1-relay-binrelay-log-index=/data/u02/bdm1-relay-bin.index# innodb-buffer&amp;cacheinnodb_buffer_pool_size = 2Ginnodb_buffer_pool_instances = 4#innodb_additional_mem_pool_size = 16Minnodb_max_dirty_pages_pct = 50# innodb loginnodb_data_file_path = ibdata1:1G:autoextendinnodb_log_file_size = 1Ginnodb_log_files_in_group = 2innodb_flush_log_at_trx_commit = 2innodb_log_buffer_size = 32M#innodb_max_undo_log_size = 4G#innodb_undo_directory = undologinnodb_undo_tablespaces = 4# innodb-ioinnodb_flush_method = O_DIRECTinnodb_io_capacity = 600innodb_io_capacity_max = 2000innodb_flush_sync = 0innodb_flush_neighbors = 0#innodb_lru_scan_depth = 4000innodb_write_io_threads = 8innodb_read_io_threads = 8innodb_purge_threads = 4innodb_page_cleaners = 4# transaction,lock#innodb_sync_spin_loops = 100#innodb_spin_wait_delay = 30innodb_lock_wait_timeout = 10innodb_print_all_deadlocks = 1innodb_rollback_on_timeout = 1innodb_open_files = 65535innodb_online_alter_log_max_size = 2G# innodb statusinnodb_status_file = 1# 注意: 开启 innodb_status_output &amp; innodb_status_output_locks 后, 可能会导致log-error文件增长较快innodb_status_output = 0innodb_status_output_locks = 0#performance_schemaperformance_schema = 1performance_schema_instrument = '%=on'#innodb monitorinnodb_monitor_enable="module_innodb"innodb_monitor_enable="module_server"innodb_monitor_enable="module_dml"innodb_monitor_enable="module_ddl"innodb_monitor_enable="module_trx"innodb_monitor_enable="module_os"innodb_monitor_enable="module_purge"innodb_monitor_enable="module_log"innodb_monitor_enable="module_lock"innodb_monitor_enable="module_buffer"innodb_monitor_enable="module_index"innodb_monitor_enable="module_ibuf_system"innodb_monitor_enable="module_buffer_page"innodb_monitor_enable="module_adaptive_hash"# MyISAMkey_buffer_size = 1024Mbulk_insert_buffer_size = 64Mmyisam_sort_buffer_size = 128Mmyisam_repair_threads = 1[mysqldump]quickmax_allowed_packet = 32M]]></content>
      <categories>
        <category>技术文档</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>mysql5.7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s部署storageclass动态创建pv(nfs&rbd)]]></title>
    <url>%2F2019%2F09%2F26%2F7-k8s%E9%83%A8%E7%BD%B2storageclass%E5%8A%A8%E6%80%81%E5%88%9B%E5%BB%BApv-nfs-rbd%2F</url>
    <content type="text"><![CDATA[考虑到k8s存储的问题, 本机目录挂载存在太大局限性, 多node多pod的服务存储急迫需要共享存储, 这里简单应用k8s storageclass nfs和rbd存储 第一部分 nfs这里单节点简单配置nfs(高并发可采用nfs+rsync+inotify或Sersync) 高并发参考 NFS高可用(NFS+keepalive+Sersync)inotify+rsync实时备份总结 12345678910#安装nfsyum install -y nfs-utils rpcbind# 创建目录mkdir /data/nfsecho "/data/nfs 172.16.76.0/24(rw,sync,no_root_squash) " &gt;&gt;/etc/exports# 启动服务systemctl start rpcbindsystemctl start nfs k8s部署storageclass环境-nfs导入外部配置12345git clone https://github.com/kubernetes-incubator/external-storage.gitcd external-storage/nfs-client/deploy#注意1 node节点需要安装nfs-utils(centos7),nfs-common(ubuntu) 修改deployment.yaml12345678910111213141516171819202122232425262728293031323334353637apiVersion: v1kind: ServiceAccountmetadata: name: nfs-client-provisioner---kind: DeploymentapiVersion: extensions/v1beta1metadata: name: nfs-client-provisionerspec: replicas: 1 strategy: type: Recreate template: metadata: labels: app: nfs-client-provisioner spec: serviceAccountName: nfs-client-provisioner containers: - name: nfs-client-provisioner image: quay.io/external_storage/nfs-client-provisioner:latest volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes env: - name: PROVISIONER_NAME value: nfs.com/nfs - name: NFS_SERVER value: 172.16.76.134 - name: NFS_PATH value: /data/nfs volumes: - name: nfs-client-root nfs: server: 172.16.76.134 path: /data/nfs 修改class.yaml1234567apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: nfsprovisioner: nfs.com/nfsparameters: archiveOnDelete: "false" rbac.yaml不用修改1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859rbac.yamlkind: ServiceAccountapiVersion: v1metadata: name: nfs-client-provisioner---kind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: nfs-client-provisioner-runnerrules: - apiGroups: [""] resources: ["persistentvolumes"] verbs: ["get", "list", "watch", "create", "delete"] - apiGroups: [""] resources: ["persistentvolumeclaims"] verbs: ["get", "list", "watch", "update"] - apiGroups: ["storage.k8s.io"] resources: ["storageclasses"] verbs: ["get", "list", "watch"] - apiGroups: [""] resources: ["events"] verbs: ["create", "update", "patch"]---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: run-nfs-client-provisionersubjects: - kind: ServiceAccount name: nfs-client-provisioner namespace: defaultroleRef: kind: ClusterRole name: nfs-client-provisioner-runner apiGroup: rbac.authorization.k8s.io---kind: RoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: leader-locking-nfs-client-provisionerrules: - apiGroups: [""] resources: ["endpoints"] verbs: ["get", "list", "watch", "create", "update", "patch"]---kind: RoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: leader-locking-nfs-client-provisionersubjects: - kind: ServiceAccount name: nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: defaultroleRef: kind: Role name: leader-locking-nfs-client-provisioner apiGroup: rbac.authorization.k8s.io 部署nfs环境(创建nfs存储类)1kubectl apply -f rbac.yaml -f class.yaml -f deployment.yaml k8s中部署nginx项目采用nfs存储部署nginx-deployment-nfs.yaml(测试nfs) 这种方式会创建一个pvc 挂载到多个pod中,这种方式适合nginx-html挂载 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465---kind: PersistentVolumeClaimapiVersion: v1metadata: name: html0-deploy-nfs annotations: volume.beta.kubernetes.io/storage-class: 'nfs'spec: accessModes: - ReadWriteMany resources: requests: storage: 1Gi---apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nginx0-deployspec: replicas: 2 template: metadata: labels: app: nginx0-deploy spec: containers: - name: nginx0-deploy image: hub.boqii.com/bq/nginx:1.15.12 ports: - containerPort: 80 volumeMounts: - name: html0-deploy-nfs mountPath: /usr/share/nginx/html - name: nginx-config mountPath: "/etc/nginx/conf.d" volumes: - name: nginx-config configMap: name: nginx-config - name: html0-deploy-nfs persistentVolumeClaim: claimName: html0-deploy-nfs---apiVersion: v1kind: ConfigMapmetadata: name: nginx-configdata: default.conf: | server &#123; listen 80; server_name localhost; root /usr/share/nginx/html/; access_log /var/log/nginx/host_access.log; error_log /var/log/nginx/host_error.log debug; location / &#123; root /usr/share/nginx/html/; index index.html index.htm index.php; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root /usr/share/nginx/html; &#125; &#125; 部署nginx-statefulset-nfs.yaml(测试nfs) 这里statefulset 方式会创建多个pvc, 每个pod的html就可以都不一样! 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758---apiVersion: apps/v1beta1kind: StatefulSetmetadata: name: nginx3spec: serviceName: "nginx" replicas: 2 volumeClaimTemplates: - metadata: name: html annotations: volume.beta.kubernetes.io/storage-class: "nfs" # 这里配置 上面创建的 storageclass 的名称 spec: accessModes: [ "ReadWriteOnce" ] resources: requests: storage: 2Gi template: metadata: labels: app: nginx spec: containers: - name: nginx image: hub.boqii.com/bq/nginx:1.15.12 volumeMounts: - mountPath: "/usr/share/nginx/html/" name: html - mountPath: "/etc/nginx/conf.d" name: nginx-config volumes: - name: nginx-config configMap: name: nginx-config---apiVersion: v1kind: ConfigMapmetadata: name: nginx-configdata: default.conf: | server &#123; listen 80; server_name localhost; root /usr/share/nginx/html/; access_log /var/log/nginx/host_access.log; error_log /var/log/nginx/host_error.log debug; location / &#123; root /usr/share/nginx/html/; index index.html index.htm index.php; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root /usr/share/nginx/html; &#125; &#125; 另外说明一下将nfs作为文件存储类似mount方式,这种方式不适用于多容器自动化部署 ,显然这种并不适合ceph rbd存储, cephfs是可以的首先需要在nfs目录创建需要挂载的目录12#例如mkdir -p /data/nfs/k8s-db-t/mysql-data-dev 在部署的yml中直接mount nfs的目录1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: mysql-server namespace: devopsspec: replicas: 1 template: metadata: labels: app: mysql-server spec: containers: - image: mysql:5.7.16 imagePullPolicy: Always name: mysql-server ports: - containerPort: 3306 protocol: TCP volumeMounts: - name: mysql-data mountPath: /var/lib/mysql resources: requests: cpu: 40m memory: 32Mi limits: cpu: "300m" memory: 256Mi env: - name: MYSQL_ROOT_PASSWORD value: "boqii.123" - name: MYSQL_DATABASE value: "gogs" - name: MYSQL_USER value: "gogs" - name: MYSQL_PASSWORD value: "gogspass" - name: TZ value: "Asia/Shanghai" volumes: - name: mysql-data nfs: server: 172.16.76.134 path: /data/nfs/k8s-db-t/mysql-data-dev---apiVersion: v1kind: Servicemetadata: name: mysql-service namespace: devopsspec: clusterIP: None selector: app: mysql-server ports: - name: http port: 3306 第二部分 cephk8s部署storageclass环境-ceph如果集群是用kubeadm部署的，由于controller-manager官方镜像中没有rbd命令，所以我们要导入外部配置12git clone https://github.com/kubernetes-incubator/external-storage.gitcd external-storage/ceph/rbd/deploy 以下整合在一个文件, 两个版本,默认 和retain storageclass-cepm.com-rbd.yaml123456789101112131415161718192021222324252627282930313233343536---apiVersion: v1data: key: QVFEYzJRbGQ1VjI5THhBQU00WUtPUU5sUVJqdWtLSWJ2VDZ0a3c9PQ==kind: Secretmetadata: name: ceph-secret-admintype: kubernetes.io/rbd---apiVersion: v1data: key: QVFEYzJRbGQ1VjI5THhBQU00WUtPUU5sUVJqdWtLSWJ2VDZ0a3c9PQ==kind: Secretmetadata: name: ceph-secret-admin namespace: ns-elastictype: kubernetes.io/rbd---apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: rbd annotations: storageclass.kubernetes.io/is-default-class: "true"provisioner: ceph.com/rbdparameters: monitors: 172.16.76.134:6789 adminId: admin adminSecretName: ceph-secret-admin adminSecretNamespace: default pool: storageclass-rbd userId: admin userSecretName: ceph-secret-admin fsType: ext4 imageFormat: "2" imageFeatures: "layering" storageclass-cepm.com-rbd-retain.yaml12345678910111213141516171819202122232425262728293031323334353637---apiVersion: v1data: key: QVFEYzJRbGQ1VjI5THhBQU00WUtPUU5sUVJqdWtLSWJ2VDZ0a3c9PQ==kind: Secretmetadata: name: ceph-secret-admintype: kubernetes.io/rbd---apiVersion: v1data: key: QVFEYzJRbGQ1VjI5THhBQU00WUtPUU5sUVJqdWtLSWJ2VDZ0a3c9PQ==kind: Secretmetadata: name: ceph-secret-admin namespace: ns-elastictype: kubernetes.io/rbd---apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: rbd-retain annotations: storageclass.kubernetes.io/is-default-class: "false"provisioner: ceph.com/rbdreclaimPolicy: Retainparameters: monitors: 172.16.76.134:6789 adminId: admin adminSecretName: ceph-secret-admin adminSecretNamespace: default pool: storageclass-rbd-retain userId: admin userSecretName: ceph-secret-admin fsType: ext4 imageFormat: "2" imageFeatures: "layering" k8s中部署nginx项目采用 ceph.com/rbd 和nfs类似, 这里省略 以上采用的是persistentVolumeClaim 方式动态分配全部内容]]></content>
      <categories>
        <category>技术文档</category>
        <category>k8s</category>
        <category>存储</category>
        <category>ceph</category>
        <category>storageclass</category>
        <category>nfs</category>
      </categories>
      <tags>
        <tag>k8s</tag>
        <tag>ceph</tag>
        <tag>k8s存储</tag>
        <tag>nfs</tag>
        <tag>storageclass</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ceph安装部署]]></title>
    <url>%2F2019%2F09%2F26%2F6-ceph%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[Ceph是一个统一的分布式存储系统，设计初衷是提供较好的性能、可靠性和可扩展性。 简单了解什么是块存储/对象存储/文件系统存储？ceph 目前提供对象存储（RADOSGW）、块存储RDB以及 CephFS 文件系统这 3 种功能。对于这3种功能介绍，分别如下： 对象存储，也就是通常意义的键值存储，其接口就是简单的GET、PUT、DEL 和其他扩展，代表主要有 Swift 、S3 以及 Gluster 等； 块存储，这种接口通常以 QEMU Driver 或者 Kernel Module 的方式存在，这种接口需要实现 Linux 的 Block Device 的接口或者 QEMU 提供的 Block Driver 接口，如 Sheepdog，AWS 的 EBS，青云的云硬盘和阿里云的盘古系统，还有 Ceph 的 RBD（RBD是Ceph面向块存储的接口）。在常见的存储中 DAS、SAN 提供的也是块存储； 文件存储，通常意义是支持 POSIX 接口，它跟传统的文件系统如 Ext4 是一个类型的，但区别在于分布式存储提供了并行化的能力，如 Ceph 的 CephFS (CephFS是Ceph面向文件存储的接口)，但是有时候又会把 GlusterFS ，HDFS 这种非POSIX接口的类文件存储接口归入此类。当然 NFS、NAS也是属于文件系统存储； 参考教程Kubernetes 集成 Ceph 后端存储教程centos7安装ceph集群 准备配置源12345678910111213141516171819202122cat &gt;/etc/yum.repos.d/ceph.repo&lt;&lt;EOF[ceph]name=cephbaseurl=http://mirrors.aliyun.com/ceph/rpm-jewel/el7/x86_64/gpgcheck=0priority=1[ceph-noarch]name=cephnoarchbaseurl=http://mirrors.aliyun.com/ceph/rpm-jewel/el7/noarch/gpgcheck=0priority=1[ceph-source]name=Ceph source packagesbaseurl=http://mirrors.163.com/ceph/rpm-jewel/el7/SRPMSenabled=0gpgcheck=1type=rpm-mdgpgkey=http://mirrors.163.com/ceph/keys/release.ascpriority=1EOF 安装过卸载123ceph-deploy purge dk1-t dk2-tceph-deploy purgedata dk1-t dk2-tceph-deploy forgetkeys 在dk2-t节点创建集群 mon模块1234567891011121314151617181920212223242526272829303132333435363738394041424344454647yum install ceph-deploy -yceph-deploy --versionmkdir /data/cephcd /data/cephceph-deploy new dk2-t# 查看配置文件ls -l# 配置ceph.conf[global]...# 如果有多个网卡，应该配置如下选项，# public network是公共网络，负责集群对外提供服务的流量# cluster network是集群网络，负载集群中数据复制传输通信等# 本次实验使用同一块网卡，生境环境建议分别使用一块网卡public network = 172.16.76.0/22cluster network = 172.16.76.0/22osd pool default size = 2# 安装 ceph 包# 如果按照官方文档安装方法 会重新配置安装官方ceph源# 由于网络问题，安装可能会出错，需要多次执行# ceph-deploy install 其实只是会安装 ceph ceph-radosgw 两个包# ceph-deploy install lab1 lab2 lab3# 推荐使用阿里源安装，因为使用ceph-deploy安装会很慢# 使用如下命令手动安装包，替代官方的 ceph-deploy install 命令# 如下操作在所有node节点上执行export CEPH_DEPLOY_REPO_URL=http://mirrors.163.com/ceph/rpm-luminous/el7export CEPH_DEPLOY_GPG_URL=http://mirrors.163.com/ceph/keys/release.asc# 先执行是因为 ceph-deploy install太慢yum install -y ceph ceph-radosgwceph-deploy install dk2-t# 部署monitor和生成keysceph-deploy mon create-initialls -l *.keyring# 复制文件到node节点ceph-deploy dk1-t dk2-t# 额外mon节点，mon节点也需要高可用ceph-deploy mon add dk1-t 在dk2-t节点创建集群 mgr模块123# 部署manager （luminous+）12及以后的版本需要部署# 本次部署 jewel 版本 ，不需要执行如下命令 ceph-deploy mgr create dk2-t 在dk2-t节点创建集群 osd模块1234# 12的版本(这里挂载一个 10G的磁盘 /dev/sdb)# create 命令一次完成准备 OSD 、部署到 OSD 节点、并激活它。 create 命令是依次执行 prepare 和 activate 命令的捷径。ceph-deploy osd create --data /dev/sdb dk2-tceph-deploy osd create --data /dev/sdc dk1-t 如何卸载osd1234567891011121314# 查看ceph osd tree# 节点状态标记为outceph osd out osd.0# 从crush中移除节点ceph osd crush remove osd.0# 删除节点ceph osd rm osd.0# 删除节点认证（不删除编号会占住）ceph auth del osd.0 查看 mon 信息12345678ceph mon dumpdumped monmap epoch 1epoch 1fsid 4620d0c7-4458-4ff9-9296-d1318058bafclast_changed 2019-06-19 14:44:41.361005created 2019-06-19 14:44:41.3610050: 172.16.76.134:6789/0 mon.dk2-t 配置文件内容 /etc/ceph/ceph.conf1234567891011[global]public network = 172.16.76.0/22cluster network = 172.16.76.0/22osd pool default size = 2fsid = 4620d0c7-4458-4ff9-9296-d1318058bafcmon_initial_members = dk2-tmon_host = 172.16.76.134auth_cluster_required = cephxauth_service_required = cephxauth_client_required = cephxmon_max_pg_per_osd = 1000 ceph 一些测试命令创建 rbd pool，名字叫做 kube1ceph osd pool create kube 256 256 如何取得admin的密钥12ceph auth get client.admin 2&gt;&amp;1 |grep "key = " |awk '&#123;print $3&#125;'AQAn/19bbb21GBAA1kc0HRWoGjeoPTRQziA03A== 测试ceph是否正常12345678910111213rbd create kube/test --size 1024 --image-format 2rbd ls kuberbd map kube/test # 如果报错, 警用 rbd info kube/test rbd feature disable kube/test exclusive-lock object-map fast-diff deep-flattenrbd map kube/testrbd showmappedmkfs.ext4 /dev/rbd0mkdir /data/rbd0mount /dev/rbd0 /data/rbd0cd /data/rbd0 &amp;&amp; echo test &gt; test.txt 在k8s 手动创建存储类创建ceph pg123456789101112131415161718192021# Total PGs = (Total_number_of_OSD * 100) / max_replication_count# pg = 1 * 100 /2 ~ 64(取2的次方数)# 这里准备创建2个pool, 每个poolceph osd pool create rbd-k8s 16# 查看ceph osd lspools# 创建imagerbd create rbd-k8s/cephimageredis --size 500M# 查看listrbd list rbd-k8s# 处理新特性# 查看inforbd info rbd-k8s/cephimageredis# 关闭exclusive-lock object-map fast-diff deep-flatten 这些特性rbd feature disable rbd-k8s/cephimageredis exclusive-lock object-map fast-diff deep-flatten 首先创建secret12#获取keygrep key /etc/ceph/ceph.client.admin.keyring |awk '&#123;printf "%s", $NF&#125;'|base64 ceph-secret.yaml1234567apiVersion: v1kind: Secretmetadata: name: ceph-secrettype: "kubernetes.io/rbd"data: key: QVFCTFo2dGNGNXFLRnhBQXBGTXJEdm5CY2k2UGtwZmZrN0JSVEE9PQ== 其次创建pv, pv是没有namespace概念的 persistentVolumeReclaimPolicy是清理规则 (retain: 不清理, Recycle: 回收) redis-ceph-pv.yml 1234567891011121314151617181920apiVersion: v1kind: PersistentVolumemetadata: name: redis2-ceph-rbd-pvspec: capacity: storage: 100Mi accessModes: - ReadWriteOnce rbd: monitors: - '172.16.76.134:6789' pool: rbd-k8s image: cephimageredis user: admin secretRef: name: ceph-secret fsType: ext4 readOnly: false persistentVolumeReclaimPolicy: Recycle 执行部署pv1kubectl create -f redis-ceph-pv.yml 然后创建pvc redis-ceph-pvc.yml 12345678910apiVersion: v1kind: PersistentVolumeClaimmetadata: name: redis2-ceph-rbd-pvcspec: accessModes: - ReadWriteOnce resources: requests: storage: 100Mi 执行部署pvc1kubectl create -f redis-ceph-pvc.yml 最后在rancher上选择挂载rbd]]></content>
      <categories>
        <category>技术文档</category>
        <category>存储</category>
        <category>ceph</category>
      </categories>
      <tags>
        <tag>k8s</tag>
        <tag>ceph</tag>
        <tag>cephfs</tag>
        <tag>k8s存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo添加看板娘]]></title>
    <url>%2F2019%2F09%2F24%2F5-hexo%E6%B7%BB%E5%8A%A0%E7%9C%8B%E6%9D%BF%E5%A8%98%2F</url>
    <content type="text"><![CDATA[hexo6 左下角添加看板娘 github地址: 张书樵大神 下载大神项目 (会说话,换人物,小游戏等功能)12cd themes/nextv6/sourcegit clone https://github.com/stevenjoezhang/live2d-widget.git github说明比较详细, 这里简单说明 由于这里是克隆到了source目录, hexo d -g的时候会生成到public目录, 相当于站点根目录了 123456# 直接开启autoload.js注释const live2d_path = "/live2d-widget/";# 修改 themes/nextv6/layout/_layout.swig, 最后一行添加如下&lt;!-- 看板娘 --&gt;&lt;script src="/live2d-widget/autoload.js"&gt;&lt;/script&gt; 一般小白简单教程(只有看鼠标方向功能) hexo 官方支持版 需要安装模板1npm install --save hexo-helper-live2d 修改主题配置文件各种宠物预览 12345678910111213141516171819202122232425# Live2D## https://github.com/EYHN/hexo-helper-live2dlive2d: enable: true # enable: false scriptFrom: local # 默认 pluginRootPath: live2dw/ # 插件在站点上的根目录(相对路径) pluginJsPath: lib/ # 脚本文件相对与插件根目录路径 pluginModelPath: assets/ # 模型文件相对与插件根目录路径 # scriptFrom: jsdelivr # jsdelivr CDN # scriptFrom: unpkg # unpkg CDN # scriptFrom: https://cdn.jsdelivr.net/npm/live2d-widget@3.x/lib/L2Dwidget.min.js # 你的自定义 url tagMode: false # 标签模式, 是否仅替换 live2d tag标签而非插入到所有页面中 debug: false # 调试, 是否在控制台输出日志 model: use: live2d-widget-model-haruto # npm-module package name # use: wanko # 博客根目录/live2d_models/ 下的目录名 # use: ./wives/wanko # 相对于博客根目录的路径 # use: https://cdn.jsdelivr.net/npm/live2d-widget-model-wanko@1.0.5/assets/wanko.model.json # 你的自定义 url display: position: left width: 150 height: 300 mobile: show: true # 手机中是否展示]]></content>
      <categories>
        <category>有趣</category>
        <category>博客</category>
        <category>二次元</category>
        <category>美化</category>
      </categories>
      <tags>
        <tag>hexo6</tag>
        <tag>特效</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo鼠标移动和鼠标点击特效]]></title>
    <url>%2F2019%2F09%2F24%2F4-hexo%E9%BC%A0%E6%A0%87%E7%A7%BB%E5%8A%A8%E5%92%8C%E9%BC%A0%E6%A0%87%E7%82%B9%E5%87%BB%E7%89%B9%E6%95%88%2F</url>
    <content type="text"><![CDATA[hexo6 鼠标添加点击出现桃心的特效 来自: Next主题个性化 所需要的js文件 未压缩 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051! function(e, t, a) &#123; function n() &#123; c( ".heart&#123;width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);&#125;.heart:after,.heart:before&#123;content: '';width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 50%;-moz-border-radius: 50%;position: fixed;&#125;.heart:after&#123;top: -5px;&#125;.heart:before&#123;left: -5px;&#125;"), o(), r() &#125; function r() &#123; for (var e = 0; e &lt; d.length; e++) d[e].alpha &lt;= 0 ? (t.body.removeChild(d[e].el), d.splice(e, 1)) : (d[e].y--, d[e].scale += .004, d[e].alpha -= .013, d[e].el.style.cssText = "left:" + d[e].x + "px;top:" + d[e].y + "px;opacity:" + d[e].alpha + ";transform:scale(" + d[e].scale + "," + d[e].scale + ") rotate(45deg);background:" + d[e].color + ";z-index:99999"); requestAnimationFrame(r) &#125; function o() &#123; var t = "function" == typeof e.onclick &amp;&amp; e.onclick; e.onclick = function(e) &#123; t &amp;&amp; t(), i(e) &#125; &#125; function i(e) &#123; var a = t.createElement("div"); a.className = "heart", d.push(&#123; el: a, x: e.clientX - 5, y: e.clientY - 5, scale: 1, alpha: 1, color: s() &#125;), t.body.appendChild(a) &#125; function c(e) &#123; var a = t.createElement("style"); a.type = "text/css"; try &#123; a.appendChild(t.createTextNode(e)) &#125; catch (t) &#123; a.styleSheet.cssText = e &#125; t.getElementsByTagName("head")[0].appendChild(a) &#125; function s() &#123; return "rgb(" + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + ")" &#125; var d = []; e.requestAnimationFrame = function() &#123; return e.requestAnimationFrame || e.webkitRequestAnimationFrame || e.mozRequestAnimationFrame || e.oRequestAnimationFrame || e.msRequestAnimationFrame || function(e) &#123; setTimeout(e, 1e3 / 60) &#125; &#125;(), n()&#125;(window, document); 压缩后 1!function(e,t,a)&#123;function n()&#123;c(".heart&#123;width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);&#125;.heart:after,.heart:before&#123;content: '';width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 50%;-moz-border-radius: 50%;position: fixed;&#125;.heart:after&#123;top: -5px;&#125;.heart:before&#123;left: -5px;&#125;"),o(),r()&#125;function r()&#123;for(var e=0;e&lt;d.length;e++)d[e].alpha&lt;=0?(t.body.removeChild(d[e].el),d.splice(e,1)):(d[e].y--,d[e].scale+=.004,d[e].alpha-=.013,d[e].el.style.cssText="left:"+d[e].x+"px;top:"+d[e].y+"px;opacity:"+d[e].alpha+";transform:scale("+d[e].scale+","+d[e].scale+") rotate(45deg);background:"+d[e].color+";z-index:99999");requestAnimationFrame(r)&#125;function o()&#123;var t="function"==typeof e.onclick&amp;&amp;e.onclick;e.onclick=function(e)&#123;t&amp;&amp;t(),i(e)&#125;&#125;function i(e)&#123;var a=t.createElement("div");a.className="heart",d.push(&#123;el:a,x:e.clientX-5,y:e.clientY-5,scale:1,alpha:1,color:s()&#125;),t.body.appendChild(a)&#125;function c(e)&#123;var a=t.createElement("style");a.type="text/css";try&#123;a.appendChild(t.createTextNode(e))&#125;catch(t)&#123;a.styleSheet.cssText=e&#125;t.getElementsByTagName("head")[0].appendChild(a)&#125;function s()&#123;return"rgb("+~~(255*Math.random())+","+~~(255*Math.random())+","+~~(255*Math.random())+")"&#125;var d=[];e.requestAnimationFrame=function()&#123;return e.requestAnimationFrame||e.webkitRequestAnimationFrame||e.mozRequestAnimationFrame||e.oRequestAnimationFrame||e.msRequestAnimationFrame||function(e)&#123;setTimeout(e,1e3/60)&#125;&#125;(),n()&#125;(window,document); 将上面的内容贴到新增的themes/nextv6/source/js/src/love.js 文件中修改themes/nextv6/layout/_layout.swig文件, 末尾添加如下内容12&lt;!-- 鼠标桃心动画 --&gt;&lt;script type="text/javascript" src="/js/src/love.js"&gt;&lt;/script&gt; hexo6 鼠标移动添加星星特效来自: 愚人节鼠标跟随特效 新增js文件 themes/nextv6/source/js/src/love2.js123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143/*! * Fairy Dust Cursor.js * - 90's cursors collection * -- https://github.com/tholman/90s-cursor-effects * -- http://codepen.io/tholman/full/jWmZxZ/ */(function fairyDustCursor() &#123; var possibleColors = ["#D61C59", "#E7D84B", "#1B8798"] var width = window.innerWidth; var height = window.innerHeight; var cursor = &#123;x: width/2, y: width/2&#125;; var particles = []; function init() &#123; bindEvents(); loop(); &#125; // Bind events that are needed function bindEvents() &#123; document.addEventListener('mousemove', onMouseMove); document.addEventListener('touchmove', onTouchMove); document.addEventListener('touchstart', onTouchMove); window.addEventListener('resize', onWindowResize); &#125; function onWindowResize(e) &#123; width = window.innerWidth; height = window.innerHeight; &#125; function onTouchMove(e) &#123; if( e.touches.length &gt; 0 ) &#123; for( var i = 0; i &lt; e.touches.length; i++ ) &#123; addParticle( e.touches[i].clientX, e.touches[i].clientY, possibleColors[Math.floor(Math.random()*possibleColors.length)]); &#125; &#125; &#125; function onMouseMove(e) &#123; cursor.x = e.clientX; cursor.y = e.clientY; addParticle( cursor.x, cursor.y, possibleColors[Math.floor(Math.random()*possibleColors.length)]); &#125; function addParticle(x, y, color) &#123; var particle = new Particle(); particle.init(x, y, color); particles.push(particle); &#125; function updateParticles() &#123; // Updated for( var i = 0; i &lt; particles.length; i++ ) &#123; particles[i].update(); &#125; // Remove dead particles for( var i = particles.length -1; i &gt;= 0; i-- ) &#123; if( particles[i].lifeSpan &lt; 0 ) &#123; particles[i].die(); particles.splice(i, 1); &#125; &#125; &#125; function loop() &#123; requestAnimationFrame(loop); updateParticles(); &#125; /** * Particles */ function Particle() &#123; this.character = "*"; this.lifeSpan = 120; //ms this.initialStyles =&#123; "position": "fixed", "top": "0", //必须加 "display": "block", "pointerEvents": "none", "z-index": "10000000", "fontSize": "20px", "will-change": "transform" &#125;; // Init, and set properties this.init = function(x, y, color) &#123; this.velocity = &#123; x: (Math.random() &lt; 0.5 ? -1 : 1) * (Math.random() / 2), y: 1 &#125;; this.position = &#123;x: x - 10, y: y - 20&#125;; this.initialStyles.color = color; console.log(color); this.element = document.createElement('span'); this.element.innerHTML = this.character; applyProperties(this.element, this.initialStyles); this.update(); document.body.appendChild(this.element); &#125;; this.update = function() &#123; this.position.x += this.velocity.x; this.position.y += this.velocity.y; this.lifeSpan--; this.element.style.transform = "translate3d(" + this.position.x + "px," + this.position.y + "px,0) scale(" + (this.lifeSpan / 120) + ")"; &#125; this.die = function() &#123; this.element.parentNode.removeChild(this.element); &#125; &#125; /** * Utils */ // Applies css `properties` to an element. function applyProperties( target, properties ) &#123; for( var key in properties ) &#123; target.style[ key ] = properties[ key ]; &#125; &#125; init();&#125;)(); 修改themes/nextv6/layout/_layout.swig文件, 末尾添加如下内容12&lt;!-- 鼠标移动星星特效 --&gt;&lt;script type="text/javascript" src="/js/src/love2.js"&gt;&lt;/script&gt;]]></content>
      <categories>
        <category>有趣</category>
        <category>博客</category>
        <category>美化</category>
      </categories>
      <tags>
        <tag>hexo6</tag>
        <tag>特效</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s遇到的一些问题统计总结]]></title>
    <url>%2F2019%2F09%2F20%2F3-k8s%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E7%BB%9F%E8%AE%A1%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[不定时更新,文章可能比较散乱,&gt;_&lt; 1. 单机版k8s pod一直是pending的问题 describe一下pod会发现错误: 1 node(s) had taints that the pod didn’t tolerate.这是因为master上存在污点,pod不会再改节点上创建两种办法: deploy 的时候加上 容忍该污点 直接取消master上的污点 12345# 取消master上污点 kubectl taint nodes --all node-role.kubernetes.io/master-# 查看taintkubectl describe node node1 2. 修改service-node-port-range 由于traefik部署需要对外开放80端口, 但默认仅允许30000以上端口 123456789# kubeadm 1.14 配置apiServer: extraArgs: authorization-mode: Node,RBAC service-node-port-range: 79-33000# kubeadm 1.10配置apiServerExtraArgs: service-node-port-range: 79-33000 3. traefik断电后重新启动报错 command traefik error: field not found, node: redirect12345看到这个错误猜测可能是用的latest镜像问题, 从hub.docker.com 查看更新了v2.0+的版本将traefik的deployment配置中 image改成 traefik:1.7重新部署后 问题解 4. 查看当前集群的(CustomResourceDefinition)12345678# 查看k8s有哪些apikubectl api-versions# 查看当前crdkubectl get crd# 其次查看该api是什么版本kubectl describe crd destinationrules.networking.istio.io]]></content>
      <categories>
        <category>技术文档</category>
        <category>k8s</category>
        <category>问题总结</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[部署elk7.2.0]]></title>
    <url>%2F2019%2F09%2F19%2F2-%E9%83%A8%E7%BD%B2elk7-2-0%2F</url>
    <content type="text"><![CDATA[说明: 121 单台k8s,本机目录挂载(未配置cephfs)2 如果replicas大于1, 就会出现多个es挂载同一个目录,会出现报错(uuid block) 1. es配置本地挂载 k8s-es-7.2.0.yml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128---apiVersion: v1kind: ServiceAccountmetadata: labels: app: elasticsearch name: elasticsearch7-admin namespace: ns-elastic7---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: elasticsearch7-admin labels: app: elasticsearchroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects: - kind: ServiceAccount name: elasticsearch7-admin namespace: ns-elastic7---apiVersion: apps/v1kind: StatefulSetmetadata: labels: app: elasticsearch role: master name: elasticsearch-master namespace: ns-elastic7spec: replicas: 1 serviceName: elasticsearch-master selector: matchLabels: app: elasticsearch role: master template: metadata: labels: app: elasticsearch role: master spec: serviceAccountName: elasticsearch7-admin restartPolicy: Always securityContext: fsGroup: 1000 containers: - name: elasticsearch-master image: hub.boqii.com/bq/elasticsearch:7.2.0 command: ["bash", "-c", "ulimit -l unlimited &amp;&amp; sysctl -w vm.max_map_count=262144 &amp;&amp; chown -R elasticsearch:elasticsearch /usr/share/elasticsearch/data &amp;&amp; exec su elasticsearch docker-entrypoint.sh"] imagePullPolicy: IfNotPresent securityContext: privileged: true ports: - containerPort: 9200 protocol: TCP - containerPort: 9300 protocol: TCP resources: requests: cpu: "50m" limits: cpu: "800m" env: - name: cluster.name value: "es_cluster" - name: node.master value: "true" - name: node.data value: "true" - name: cluster.initial_master_nodes value: "elasticsearch-master-0" # 根据副本数和name配置 - name: discovery.zen.ping_timeout value: "5s" - name: node.ingest value: "false" - name: ES_JAVA_OPTS value: "-Xms1g -Xmx1g" - name: "discovery.zen.ping.unicast.hosts" value: "elasticsearch-discovery" # Disvocery Service - name: "http.cors.enabled" value: "true" - name: "http.cors.allow-origin" value: "*" volumeMounts: - name: elasticsearch-data-volume mountPath: /usr/share/elasticsearch/data volumes: - name: elasticsearch-data-volume hostPath: path: /data/k8s-container/elk-7.2.0/es-7.2.0/data---apiVersion: v1kind: Servicemetadata: labels: app: elasticsearch name: elasticsearch-discovery namespace: ns-elastic7spec: publishNotReadyAddresses: true ports: - name: transport port: 9300 targetPort: 9300 selector: app: elasticsearch role: master---kind: ServiceapiVersion: v1metadata: labels: app: elasticsearch name: elasticsearch-service namespace: ns-elastic7spec: type: NodePort ports: - port: 9200 targetPort: 9200 nodePort: 19230 protocol: TCP selector: app: elasticsearch 2. es配置nfs动态挂载 k8s-es-7.2.0-nfs.yml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129---apiVersion: v1kind: ServiceAccountmetadata: labels: app: elasticsearch name: elasticsearch-admin namespace: ns-elastic---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: elasticsearch-admin labels: app: elasticsearchroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects: - kind: ServiceAccount name: elasticsearch-admin namespace: ns-elastic---apiVersion: apps/v1kind: StatefulSetmetadata: labels: app: elasticsearch role: master name: elasticsearch-master namespace: ns-elasticspec: replicas: 2 volumeClaimTemplates: - metadata: name: elasticsearch-data-nfs annotations: volume.beta.kubernetes.io/storage-class: "nfs" spec: accessModes: [ "ReadWriteOnce" ] resources: requests: storage: 2Gi serviceName: elasticsearch-master selector: matchLabels: app: elasticsearch role: master template: metadata: labels: app: elasticsearch role: master spec: serviceAccountName: elasticsearch-admin restartPolicy: Always securityContext: fsGroup: 1000 containers: - name: elasticsearch-master image: elasticsearch:7.2.0 command: ["bash", "-c", "ulimit -l unlimited &amp;&amp; sysctl -w vm.max_map_count=262144 &amp;&amp; chown -R elasticsearch:elasticsearch /usr/share/elasticsearch/data &amp;&amp; exec su elasticsearch docker-entrypoint.sh"] imagePullPolicy: IfNotPresent volumeMounts: - name: elasticsearch-data-nfs mountPath: /usr/share/elasticsearch/data securityContext: privileged: true ports: - containerPort: 9200 protocol: TCP - containerPort: 9300 protocol: TCP env: - name: cluster.name value: "es_cluster" - name: node.master value: "true" - name: node.data value: "true" - name: cluster.initial_master_nodes value: "elasticsearch-master-0,elasticsearch-master-1" # 根据副本数和name配置 - name: discovery.zen.ping_timeout value: "5s" - name: node.ingest value: "false" - name: ES_JAVA_OPTS value: "-Xms1g -Xmx1g" - name: "discovery.zen.ping.unicast.hosts" value: "elasticsearch-discovery" # Disvocery Service - name: "http.cors.enabled" value: "true" - name: "http.cors.allow-origin" value: "*"---apiVersion: v1kind: Servicemetadata: labels: app: elasticsearch name: elasticsearch-discovery namespace: ns-elasticspec: publishNotReadyAddresses: true ports: - name: transport port: 9300 targetPort: 9300 selector: app: elasticsearch role: master---kind: ServiceapiVersion: v1metadata: labels: app: elasticsearch name: elasticsearch-service namespace: ns-elasticspec: type: NodePort ports: - port: 9200 targetPort: 9200 nodePort: 19220 protocol: TCP selector: app: elasticsearch 3. kibana配置k8s-kibana-7.2.0.yml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485apiVersion: v1kind: ConfigMapmetadata: name: kibana-config namespace: ns-elastic7 labels: elastic-app: kibanadata: kibana.yml: | server.name: kibana server.host: "0" elasticsearch.hosts: [ "http://elasticsearch-service:9200" ] xpack.monitoring.ui.container.elasticsearch.enabled: true---kind: DeploymentapiVersion: apps/v1beta2metadata: labels: elastic-app: kibana name: kibana namespace: ns-elastic7spec: replicas: 1 revisionHistoryLimit: 10 selector: matchLabels: elastic-app: kibana template: metadata: labels: elastic-app: kibana spec: containers: - name: kibana image: hub.boqii.com/bq/kibana:7.2.0 ports: - containerPort: 5601 protocol: TCP resources: requests: cpu: "50m" limits: cpu: "800m" volumeMounts: - name: kibana-config mountPath: /usr/share/kibana/config volumes: - name: kibana-config configMap: name: kibana-config tolerations: - key: node-role.kubernetes.io/master effect: NoSchedule---kind: ServiceapiVersion: v1metadata: labels: elastic-app: kibana name: kibana-service namespace: ns-elastic7spec: ports: - port: 5601 targetPort: 5601 selector: elastic-app: kibana type: NodePort---apiVersion: extensions/v1beta1kind: Ingressmetadata: labels: elastic-app: kibana name: kibana-ingress namespace: ns-elastic7spec: rules: - host: elk-kibana-dev.boqii.com http: paths: - backend: serviceName: kibana-service servicePort: 5601 4. logstash配置 本地挂载 k8s-logstash-7.2.0.yml 4.1 config/pipelines.yml 12- pipeline.id: main path.config: "/usr/share/logstash/config/pipeline/*.conf" 4.2 首先配置grok规则 config/pipeline/logstash.conf 12345678910111213141516171819202122input &#123; udp &#123; port =&gt; "10000" &#125; &#125; filter &#123; grok &#123; match =&gt; &#123; "message" =&gt; "\&#123;\"id\":\"(?&lt;id&gt;(.)*)\",\"tag\":\"(?&lt;tag&gt;(.)*)\",\"title\":\"%&#123;GREEDYDATA:title&#125;(?&lt;title&gt;(.|\r|\n)*)\",\"value\":\"%&#123;GREEDYDATA:value&#125;(?&lt;value&gt;(.|\r|\n)*)\",\"createdAt\":\"(?&lt;createdAt&gt;\S+ \S+)\",\"Telephone\":\"(?&lt;Telephone&gt;(.)*)\",\"uid\":\"(?&lt;uid&gt;(.)*)\",\"updateTime\":\"(?&lt;updateTime&gt;(.)*)\",\"appVersion\":\"(?&lt;appVersion&gt;(.)*)\",\"mobileModel\":\"(?&lt;mobileModel&gt;(.)*)\",\"osVersion\":\"(?&lt;osVersion&gt;(.)*)\",\"channel\":\"(?&lt;channel&gt;(.)*)\",\"UDID\":\"(?&lt;UDID&gt;(.)*)\"\&#125;" &#125; &#125; &#125;output &#123; elasticsearch &#123; hosts =&gt; [ "http://elasticsearch-service:9200" ] index =&gt; "k8s2-dev-%&#123;+YYYY.MM.dd&#125;" &#125; &#125; 4.3 配置文件 k8s-logstash-7.2.0.yml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455---kind: DeploymentapiVersion: apps/v1beta2metadata: labels: elastic-app: logstash name: logstash namespace: ns-elasticspec: replicas: 1 revisionHistoryLimit: 10 selector: matchLabels: elastic-app: logstash template: metadata: labels: elastic-app: logstash spec: containers: - name: logstash image: hub.boqii.com/bq/logstash:7.2.0 ports: - containerPort: 10000 protocol: UDP volumeMounts: - name: logstash-config mountPath: /usr/share/logstash/config volumes: - name: logstash-config hostPath: path: /data/k8s-pod/elk-7.2.0/logstash-7.2.0/config tolerations: - key: node-role.kubernetes.io/master effect: NoSchedule---kind: ServiceapiVersion: v1metadata: labels: elastic-app: logstash name: logstash-service namespace: ns-elasticspec: type: NodePort ports: - port: 10000 targetPort: 10000 nodePort: 10000 protocol: UDP selector: elastic-app: logstash type: NodePort---]]></content>
      <categories>
        <category>技术文档</category>
        <category>k8s</category>
        <category>elk</category>
        <category>elk7</category>
        <category>elasticsearch7</category>
      </categories>
      <tags>
        <tag>k8s</tag>
        <tag>elk</tag>
        <tag>elk7</tag>
        <tag>elasticsearch7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[首次搭建hexo博客系统]]></title>
    <url>%2F2019%2F09%2F19%2F%E9%A6%96%E6%AC%A1%E6%90%AD%E5%BB%BAhexo%E5%8D%9A%E5%AE%A2%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[1 安装hexo 1.1 在mac上安装 12# 安装nodebrew install node npm 1.2 在linux安装 123# 安装node10curl -sL https://rpm.nodesource.com/setup_10.x | bash -yum install -y nodejs 1.3 安装hexo 12# 安装hexonpm install -g hexo 2 初始化123456789101112cd /data/github/# 初始化hexo init blog# 框架安装npm install#安装 Hexo 关于启动服务器的插件npm install hexo-server --save# 启动服务器, 本地查看效果, 如果不指定端口，默认为4000hexo server 3 主题和配置 下载主题：https://github.com/theme-next/hexo-theme-next 12unzip hexo-theme-next-master.zipmv hexo-theme-next-master $blog/themes/ 修改主题配置 _config.yml 中的其他属性 12345title: Zhangzhiwei's Blog...theme: hexo-theme-next...scheme: Mist 4. 编写更新博客 创建博客 1hexo new '第一个博客' cat source/_posts/第一个博客.md 123456title: 第一个博客date: 2019-09-19 16:58:01tags: - hexocategories: - hexo学习 github 创建一个Repository仓库 1231. 仓库名字必须是 xxx.github.io2. 在settings中 勾选Template repository3. 记得添加自己的ssh github配置 12 # 安装 hexo 关于 git 的组件npm install hexo-deployer-git --save 在_config.yml 中为 git 添加配置 1234deploy: type: git repository: git@github.com:*/*.github.io.git branch: master 查看是否能提交代码github 1ssh -T -ai ~/.ssh/id_rsa git@github.com 部署 1234hexo ghexo d或者hexo d -g 5. next6让首页文字预览显示 5.1 方法一: 自动形成摘要,默认截取的长度为 150 字符 1231. 找到主题的配置文件(themes/next/_config.yml)2. 修改auto_excerpt,把enable改为对应的false改为true3. hexo d -g 5.2 方法二: 博客内容中添加 &lt; !–more–&gt; 123# 安装nodebrew install node npm &lt;!-- more --&gt; 5.3 方法三: 在文章中的front-matter中添加description，并提供文章摘录,这种方式只会在首页列表中显示文章的摘要内容，进入文章详情后不会再显示。 1234567891011title: 部署elk7.2.0date: 2019-09-19 17:59:53copyright: truetags: - k8s - elk - elk7categories: - 技术文档 - elkdescription: 本文主要是简单单机版部署elk7体验, 并非高可用集群方式部署, 部分安装步骤省略. 主要是记录yml配置文件, 仅供参考. 详细内容请点击下方阅读全文, 非常感谢! 6. next6添加搜索功能123456789101. npm install hexo-generator-searchdb --save2. 全局配置文件_config.ymlsearch: path: search.xml field: post format: html limit: 100003. 修改主题的_config.ymllocal_search: enable: true 7. next6 Mist字体的 首页文章间距和首页页宽,字体 7.1 首页文章间距 12345增加一些内容: source/css/_schemes/Mist/_posts-expanded.styl.posts-expand .post &#123; margin-top: 30px; margin-bottom: 30px;&#125; 7.2 页宽 1234source/css/_variables/base.styl$content-desktop = 900px$content-desktop-large = 1000px$content-desktop-largest = 1100px 7.3 字体大小 1234567891011themes/next/source/css/_variables/base.styl$font-size-base = 0.95em;$font-size-base = unit(hexo-config('font.global.size'), em) if hexo-config('font.global.size') is a 'unit';$font-size-smallest = .75em;$font-size-smaller = .8125em;$font-size-small = .855em;$font-size-medium = 0.95em;$font-size-large = 0.975em;$font-size-larger = 1.em;$font-size-largest = 1.125em; 8. 添加网格 8.1 自定义方式修改 1234567891011121314# 新创建自定义文件cat themes/next/source/css/_custom/custom.styl// 主页文章添加阴影效果.post &#123;margin-top: 60px;margin-bottom: 60px;padding: 25px;-webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5);-moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5);&#125;# 修改config文件vim ./themes/next/_config.ymlcustom: custom 8.2 next6版本修改方式 参考: hexo6–next美化整理 修改 themes/next/layout/_layout.swig 1234&#123;% if theme.canvas_nest %&#125;&lt;script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"&gt;&lt;/script&gt;&#123;% endif %&#125; 将上述代码防止在&lt; /body&gt; 前就可以了(注意不要放在&lt; /head&gt;的后面)。 修改主题的_config.yml 123456canvas_nest: true//color: 线条颜色, 默认: '0,0,0'；三个数字分别为(R,G,B)//opacity: 线条透明度（0~1）, 默认: 0.5//count: 线条的总数量, 默认: 150//zIndex: 背景的z-index属性，css属性用于控制所在层的位置, 默认: -1 注意:我这里打开提示缺少 canvas-nest.min.js文件,这里是手动copy的一份写到 source/lib/canvas-nest/canvas-nest.min.js 1!function()&#123;function o(w,v,i)&#123;return w.getAttribute(v)||i&#125;function j(i)&#123;return document.getElementsByTagName(i)&#125;function l()&#123;var i=j("script"),w=i.length,v=i[w-1];return&#123;l:w,z:o(v,"zIndex",-1),o:o(v,"opacity",0.5),c:o(v,"color","0,0,0"),n:o(v,"count",99)&#125;&#125;function k()&#123;r=u.width=window.innerWidth||document.documentElement.clientWidth||document.body.clientWidth,n=u.height=window.innerHeight||document.documentElement.clientHeight||document.body.clientHeight&#125;function b()&#123;e.clearRect(0,0,r,n);var w=[f].concat(t);var x,v,A,B,z,y;t.forEach(function(i)&#123;i.x+=i.xa,i.y+=i.ya,i.xa*=i.x&gt;r||i.x&lt;0?-1:1,i.ya*=i.y&gt;n||i.y&lt;0?-1:1,e.fillRect(i.x-0.5,i.y-0.5,1,1);for(v=0;v&lt;w.length;v++)&#123;x=w[v];if(i!==x&amp;&amp;null!==x.x&amp;&amp;null!==x.y)&#123;B=i.x-x.x,z=i.y-x.y,y=B*B+z*z;y&lt;x.max&amp;&amp;(x===f&amp;&amp;y&gt;=x.max/2&amp;&amp;(i.x-=0.03*B,i.y-=0.03*z),A=(x.max-y)/x.max,e.beginPath(),e.lineWidth=A/2,e.strokeStyle="rgba("+s.c+","+(A+0.2)+")",e.moveTo(i.x,i.y),e.lineTo(x.x,x.y),e.stroke())&#125;&#125;w.splice(w.indexOf(i),1)&#125;),m(b)&#125;var u=document.createElement("canvas"),s=l(),c="c_n"+s.l,e=u.getContext("2d"),r,n,m=window.requestAnimationFrame||window.webkitRequestAnimationFrame||window.mozRequestAnimationFrame||window.oRequestAnimationFrame||window.msRequestAnimationFrame||function(i)&#123;window.setTimeout(i,1000/45)&#125;,a=Math.random,f=&#123;x:null,y:null,max:20000&#125;;u.id=c;u.style.cssText="position:fixed;top:0;left:0;z-index:"+s.z+";opacity:"+s.o;j("body")[0].appendChild(u);k(),window.onresize=k;window.onmousemove=function(i)&#123;i=i||window.event,f.x=i.clientX,f.y=i.clientY&#125;,window.onmouseout=function()&#123;f.x=null,f.y=null&#125;;for(var t=[],p=0;s.n&gt;p;p++)&#123;var h=a()*r,g=a()*n,q=2*a()-1,d=2*a()-1;t.push(&#123;x:h,y:g,xa:q,ya:d,max:6000&#125;)&#125;setTimeout(function()&#123;b()&#125;,100)&#125;();% zhangzw@MacBook-Pro  /data/github/blog   master ●  9. 添加评论功能 9.1 注册leancloud 1注册-&gt; 验证邮箱-&gt; 实名认证 -&gt; 设置获取appid和appkey 9.2 修改配置文件 123456valine: enable: true appid: 'appid' appkey: 'appkey' placeholder: "ヾﾉ≧∀≦)o 来呀！快活呀！~啦啦啦~ 啦啦啦啦~" visitor: true //这个打开页会统计文章阅读数 10. next6添加字数统计 和阅读时长 hexo-symbols-count-time 10.1 安装node扩展 1npm install hexo-symbols-count-time --save 10.2 修改全局配置 _config.yml 123456symbols_count_time: symbols: true time: true total_symbols: true total_time: true exclude_codeblock: false 10.3 修改主题配置 _config.yml 1234567symbols_count_time: separated_meta: true item_text_post: true item_text_total: false awl: 4 wpm: 275 suffix: mins. 11. next6 文章置顶功能 11.1 安装node扩展 12npm uninstall hexo-generator-index --savenpm install hexo-generator-index-pin-top --save 11.2 在文章开头添加置顶标识 1top: 10 11.3 首页添加明显置顶标识 123456themes/next/layout/_macro/post.swig 在&lt;div class="post-meta"&gt; 下添加如下代码&#123;% if post.top %&#125; &lt;i class="fa fa-thumb-tack"&gt;&lt;/i&gt; &lt;font color=green&gt;置顶&lt;/font&gt; &lt;span class="post-meta-divider"&gt;|&lt;/span&gt;&#123;% endif %&#125; 12. next6 开启标签和分类 12.1 创建tags相关目录 12hexo new page tagshexo new page categories 12.2 开启tags标签和分类 123vim themes/next/_config.ymltags: /tags/ || tagscategories: /categories/ || th 12.3 修改tags站点文件 12345678cat source/tags/index.md---title: tagsdate: 2019-09-24 10:08:59type: "tags"layout: "tags"comments: false--- 12.4 修改categories站点文件 12345678cat source/categories/index.md---title: categoriesdate: 2019-09-24 10:09:55type: "categories"layout: "categories"comments: false--- 12.5 去掉xxx.github.io/tags/ 页面的post-title(因为我的这个css左对齐了,默认是居中,所以很丑) 123# 注释下面这段代码vim themes/nextv/layout/page.swig &lt;!-- &#123;% include '_partials/page/page-header.swig' %&#125; --&gt; 12.6 文章中多个tag和categories 123456tags: - k8s - k8s安装categories: - [k8s,安装] - [技术文档]]]></content>
      <categories>
        <category>有趣</category>
        <category>博客</category>
        <category>美化</category>
      </categories>
      <tags>
        <tag>hexo6</tag>
        <tag>hexo美化</tag>
      </tags>
  </entry>
</search>
