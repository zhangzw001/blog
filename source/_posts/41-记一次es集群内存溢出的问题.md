---
title: 记一次es集群内存溢出的问题
copyright: true
date: 2020-03-19 10:26:49
tags:
<<<<<<< HEAD
  - elasticsearch5
categories:
  - [elk,elasticsearch5]
---
es机器报警磁盘 / 空间不足,查看是生成了 .hprof 文件, 内存溢出的典型特征
<!--more -->


<center>
<img src="http://zhangzw001.github.io/images/dockerniu.jpeg" width = "100" height = "100" style="border: 0"/>
</center>

以上问题主要是两点
1. 由于elasticsearch用户家目录是/home/elasticsearch, 所以内存溢出时 写的.hprof文件会生成到家目录, 并且大小有6G+, 这会导致/目录磁盘空间不足报警, 是否可以设置该日志目录? 或者取巧设置elasticsearch家目录到/data挂载盘上?
2. 内存溢出的问题, 是否可以优化并解决


### 问题1 我这里并未找到设置.hprof文件的生成目录路径设置, 所以我就将根目录做了一个链接
```
mv /home/elasticsearch /data/
ln -s /data/elasticsearch /home/elasticsearch
或者修改elasticsearch用户的家目录(不过需要用户没有在login中)
lsof |grep elasticsearch
usermod -d /data/elasticsearch elasticsearch
```




### 问题2 内存溢出的问题,我们设置  indices.fielddata.cache.size:  20% 
> [elasticsearch2.x 限制内存使用](https://www.elastic.co/guide/cn/elasticsearch/guide/current/_limiting_memory_usage.html#fielddata-size)

indices.fielddata.cache.size 控制为 fielddata 分配的堆空间大小。 当你发起一个查询，分析字符串的聚合将会被加载到 fielddata，如果这些字符串之前没有被加载过。如果结果中 fielddata 大小超过了指定 大小 ，其他的值将会被回收从而获得空间。

默认情况下，设置都是 unbounded ，Elasticsearch 永远都不会从 fielddata 中回收数据。
这个默认设置是刻意选择的：fielddata 不是临时缓存。它是驻留内存里的数据结构，必须可以快速执行访问，而且构建它的代价十分高昂。如果每个请求都重载数据，性能会十分糟糕。


### 监控fielddata

- 按索引使用 indices-stats API ：
```
GET /_stats/fielddata?fields=*
```
- 按节点使用 nodes-stats API ：
```
GET /_nodes/stats/indices/fielddata?fields=*
```
- 按索引节点：
```
GET /_nodes/stats/indices/fielddata?level=indices&fields=*
```

使用设置 ?fields=* ，可以将内存使用分配到每个字段。


### 断路器

机敏的读者可能已经发现 fielddata 大小设置的一个问题。fielddata 大小是在数据加载 之后 检查的。 如果一个查询试图加载比可用内存更多的信息到 fielddata 中会发生什么？答案很丑陋：我们会碰到 OutOfMemoryException 。

Elasticsearch 包括一个 fielddata 断熔器 ，这个设计就是为了处理上述情况。 断熔器通过内部检查（字段的类型、基数、大小等等）来估算一个查询需要的内存。它然后检查要求加载的 fielddata 是否会导致 fielddata 的总量超过堆的配置比例。

如果估算查询的大小超出限制，就会 触发 断路器，查询会被中止并返回异常。这都发生在数据加载 之前 ，也就意味着不会引起 OutOfMemoryException 。

```
可用的断路器（Available Circuit Breakers）

Elasticsearch 有一系列的断路器，它们都能保证内存不会超出限制：

indices.breaker.fielddata.limit
fielddata 断路器默认设置堆的 60% 作为 fielddata 大小的上限。
indices.breaker.request.limit
request 断路器估算需要完成其他请求部分的结构大小，例如创建一个聚合桶，默认限制是堆内存的 40%。
indices.breaker.total.limit
total 揉合 request 和 fielddata 断路器保证两者组合起来不会使用超过堆内存的 70%。
```

断路器的限制可以在文件 config/elasticsearch.yml 中指定，可以动态更新一个正在运行的集群：
```
PUT /_cluster/settings
{
  "persistent" : {
    "indices.breaker.fielddata.limit" : "40%" 
  }
}
```

最好为断路器设置一个相对保守点的值。 记住 fielddata 需要与 request 断路器共享堆内存、索引缓冲内存和过滤器缓存。Lucene 的数据被用来构造索引，以及各种其他临时的数据结构。 正因如此，它默认值非常保守，只有 60% 。过于乐观的设置可能会引起潜在的堆栈溢出（OOM）异常，这会使整个节点宕掉。


> 在 Fielddata的大小 中，我们提过关于给 fielddata 的大小加一个限制，从而确保旧的无用 fielddata 被回收的方法。 indices.fielddata.cache.size 和 indices.breaker.fielddata.limit 之间的关系非常重要。 如果断路器的限制低于缓存大小，没有数据会被回收。为了能正常工作，断路器的限制 必须 要比缓存大小要高。






### 在设置 Elasticsearch 堆大小时需要通过 $ES_HEAP_SIZE 环境变量应用两个规则：

1 不要超过可用 RAM 的 50%
Lucene 能很好利用文件系统的缓存，它是通过系统内核管理的。如果没有足够的文件系统缓存空间，性能会受到影响。 此外，专用于堆的内存越多意味着其他所有使用 doc values 的字段内存越少。
2 不要超过 32 GB
如果堆大小小于 32 GB，JVM 可以利用指针压缩，这可以大大降低内存的使用：每个指针 4 字节而不是 8 字节。
=======
---
>>>>>>> f0eb8557502bb7b89616955eaea606fc1b067664
